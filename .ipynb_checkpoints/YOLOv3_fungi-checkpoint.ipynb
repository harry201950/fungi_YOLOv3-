{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64759373",
   "metadata": {},
   "source": [
    "# YOLOv3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361c5d7b",
   "metadata": {},
   "source": [
    "## YOLOv3의 합성곱과 Residual(yolo.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20444768",
   "metadata": {},
   "source": [
    "### 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a5c4e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Darknet-53 for yolo v3.\"\"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dense, add, Activation, ELU, AveragePooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879b53f4",
   "metadata": {},
   "source": [
    "### 합성곱함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155b347a",
   "metadata": {},
   "source": [
    "#### BatchNormalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66820a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormalization(layers.BatchNormalization):\n",
    "    # \"동결 상태(Frozen state)\"와 \"추론 모드(Inference mode)\"는 별개의 개념입니다. \n",
    "    # 'layer.trainable=False' 이면 레이어를 동결시킵니다. 이것은 훈련하는 동안 내부 상태 즉, 가중치가 바뀌지 않습니다.\n",
    "    # 그런데 layer.trainable=False이면 추론 모드로 실행됩니다. \n",
    "    # 레이어는 추론모드에서 현재 배치의 평균 및 분산을 사용하는 대신 현재 배치를 정규화하기 위해 이동 평균과 이동 분산을 사용합니다.\n",
    "    def call(self, x, training=False):\n",
    "        if not training:\n",
    "            training = tf.constant(False)\n",
    "        training = tf.logical_and(training, self.trainable)\n",
    "        return super().call(x, training)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eff2b2",
   "metadata": {},
   "source": [
    "#### convolutional()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11eb8453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional(input_layer, filters, kernel_size,\n",
    "                  downsample=False, activate=True, bn=True):\n",
    "    if downsample:\n",
    "        input_layer = layers.ZeroPadding2D(((1, 0), (1, 0)))(input_layer)\n",
    "        padding = 'valid'\n",
    "        strides = 2\n",
    "    else:\n",
    "        strides = 1\n",
    "        padding = 'same'\n",
    "\n",
    "    kernel_init = tf.random_normal_initializer(stddev=0.01)\n",
    "    conv = layers.Conv2D(filters=filters,\n",
    "                         kernel_size=kernel_size,\n",
    "                         strides=strides, padding=padding, \n",
    "                         use_bias=not bn,\n",
    "                         kernel_initializer=kernel_init,\n",
    "                         kernel_regularizer=l2(0.0005) #5e-4\n",
    "                        )(input_layer)\n",
    "    if bn:\n",
    "        conv = BatchNormalization()(conv)\n",
    "    if activate:\n",
    "        conv = layers.ELU(alpha=0.1)(conv)\n",
    "\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a162e72",
   "metadata": {},
   "source": [
    "### 레지듀얼 블록"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b504eeee",
   "metadata": {},
   "source": [
    "#### residual_block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "236046cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(input_layer, filter_num1, filter_num2):\n",
    "    short_cut = input_layer\n",
    "    conv = convolutional(input_layer, filters=filter_num1, kernel_size=(1,1))\n",
    "    conv = convolutional(conv, filters=filter_num2, kernel_size=(3,3))\n",
    "    residual_output = short_cut + conv\n",
    "    return residual_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14da4f8",
   "metadata": {},
   "source": [
    "## 다크넷 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e441c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def darknet53(input_data):\n",
    "    # convolutional(input_layer, filters, kernel_size)\n",
    "    # residual_block(input_layer, filter_num1, filter_num2):\n",
    "    input_data = convolutional(input_data, 32, (3,3))\n",
    "    \n",
    "    input_data = convolutional(input_data, 64, (3,3), downsample=True)\n",
    "\n",
    "    for i in range(1):\n",
    "        input_data = residual_block(input_data,  32, 64)\n",
    "\n",
    "    input_data = convolutional(input_data, 128, (3,3), downsample=True)\n",
    "\n",
    "    for i in range(2):\n",
    "        input_data = residual_block(input_data, 64, 128)\n",
    "\n",
    "    input_data = convolutional(input_data, 256, (3,3), downsample=True)\n",
    "\n",
    "    for i in range(8):\n",
    "        input_data = residual_block(input_data, 128, 256)\n",
    "\n",
    "    route_1 = input_data\n",
    "    \n",
    "    input_data = convolutional(input_data, 512, (3,3), downsample=True)\n",
    "\n",
    "    for i in range(8):\n",
    "        input_data = residual_block(input_data, 256, 512)\n",
    "\n",
    "    route_2 = input_data\n",
    "    input_data = convolutional(input_data, 1024, (3,3), downsample=True)\n",
    "\n",
    "    for i in range(4):\n",
    "        input_data = residual_block(input_data, 512, 1024)\n",
    "    \n",
    "    input_data = layers.GlobalAveragePooling2D((1, 1))\n",
    "\n",
    "    return route_1, route_2, input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59faf35",
   "metadata": {},
   "source": [
    "## upsample() - 업샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c848bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(input_layer):\n",
    "    width, height = input_layer.shape[1], input_layer.shape[2]\n",
    "    output_layer = tf.image.resize(input_layer, (width*2, height*2), \n",
    "                                   method='nearest')\n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f165733",
   "metadata": {},
   "source": [
    "## YOLOv3 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39b47029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def YOLOv3(input_layer, num_class):\n",
    "    # Darknet-53을 실행하고 그 결과를 받음\n",
    "    route_1, route_2, conv = darknet53(input_layer)\n",
    "    \n",
    "    conv = convolutional(conv, 512, (1,1))\n",
    "    conv = convolutional(conv, 1024, (3,3))\n",
    "    conv = convolutional(conv, 512, (1,1))\n",
    "    conv = convolutional(conv, 1024, (3,3))\n",
    "    conv = convolutional(conv, 512, (1,1))\n",
    "    conv_lobj_branch = convolutional(conv, 1024, (3,3))\n",
    "    \n",
    "    # conv_lbbox는 큰 객체를 예측하기 위해 사용, Shape = [None, 13, 13, 255] \n",
    "    conv_lbbox = convolutional(conv_lobj_branch, \n",
    "                               3*(num_class+5), (1,1),\n",
    "                               activate=False, bn=False)\n",
    "    \n",
    "    conv = convolutional(conv, 256, (1,1))\n",
    "    # 최근방법(nearest)을 이용하여 업샘플링\n",
    "    # 이렇게 하면 업샘플링시 학습이 필요 없으므로 인공신경망 파라미터를 줄인다.\n",
    "    conv = upsample(conv)\n",
    "\n",
    "    conv = tf.concat([conv, route_2], axis=-1)\n",
    "    conv = convolutional(conv, 256, (1,1))\n",
    "    conv = convolutional(conv, 512, (3,3))\n",
    "    conv = convolutional(conv, 256, (1,1))\n",
    "    conv = convolutional(conv, 512, (3,3))\n",
    "    conv = convolutional(conv, 256, (1,1))\n",
    "    conv_mobj_branch = convolutional(conv, 512, (3,3))\n",
    "\n",
    "    # conv_mbbox는 중간 크기 객체를 예측하기 위해 사용, shape = [None, 26, 26, 255]\n",
    "    conv_mbbox = convolutional(conv_mobj_branch,\n",
    "                               3*(num_class+5), (1,1),\n",
    "                               activate=False, bn=False)\n",
    "\n",
    "    conv = convolutional(conv, 128, (1,1))\n",
    "    conv = upsample(conv)\n",
    "\n",
    "    conv = tf.concat([conv, route_1], axis=-1)\n",
    "    conv = convolutional(conv, 128, (1,1))\n",
    "    conv = convolutional(conv, 256, (3,3))\n",
    "    conv = convolutional(conv, 128, (1,1))\n",
    "    conv = convolutional(conv, 256, (3,3))\n",
    "    conv = convolutional(conv, 128, (1,1))\n",
    "    conv_sobj_branch = convolutional(conv, 256, (3,3))\n",
    "    \n",
    "    # conv_sbbox는 작은 객체를 예측하기 위해 사용, shape = [None, 52, 52, 255]\n",
    "    conv_sbbox = convolutional(conv_sobj_branch, \n",
    "                               3*(num_class+5), (1,1),\n",
    "                               activate=False, bn=False)\n",
    "        \n",
    "    return [conv_sbbox, conv_mbbox, conv_lbbox]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ccef6",
   "metadata": {},
   "source": [
    "## 합성곱 신경망의 출력을 디코딩 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efab343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "YOLO_STRIDES  = [8, 16, 32]\n",
    "YOLO_ANCHORS  = [[[10,  13], [16,   30], [33,   23]],\n",
    "                 [[30,  61], [62,   45], [59,  119]],\n",
    "                 [[116, 90], [156, 198], [373, 326]]]\n",
    "STRIDES       = np.array(YOLO_STRIDES)\n",
    "ANCHORS       = (np.array(YOLO_ANCHORS).T/STRIDES).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d8e3488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(conv_output, num_class, i=0):\n",
    "    conv_shape       = tf.shape(conv_output)\n",
    "    batch_size       = conv_shape[0]\n",
    "    output_size      = conv_shape[1]\n",
    "\n",
    "    conv_output = tf.reshape(conv_output, \n",
    "                             (batch_size, output_size, output_size, \n",
    "                              3, num_class+5))\n",
    "\n",
    "    conv_raw_dxdy = conv_output[:, :, :, :, 0:2] # 상자의 x, y위치\n",
    "    conv_raw_dwdh = conv_output[:, :, :, :, 2:4] # 상자의 가로, 세로 크기\n",
    "    conv_raw_conf = conv_output[:, :, :, :, 4:5] # 상자의 신뢰도(confidence)\n",
    "    conv_raw_prob = conv_output[:, :, :, :, 5: ] # 클래스별 확률\n",
    "\n",
    "    # next need Draw the grid. Where output_size is equal to 13, 26 or 52  \n",
    "    y = tf.range(output_size, dtype=tf.int32)\n",
    "    y = tf.expand_dims(y, -1)\n",
    "    y = tf.tile(y, [1, output_size])\n",
    "    x = tf.range(output_size, dtype=tf.int32)\n",
    "    x = tf.expand_dims(x, 0)\n",
    "    x = tf.tile(x, [output_size, 1])\n",
    "\n",
    "    xy_grid = tf.concat([x[:, :, tf.newaxis], y[:, :, tf.newaxis]], axis=-1)\n",
    "    xy_grid = tf.tile(xy_grid[tf.newaxis, :, :, tf.newaxis, :], \n",
    "                      [batch_size, 1, 1, 3, 1])\n",
    "    xy_grid = tf.cast(xy_grid, tf.float32)\n",
    "\n",
    "    # 상자의 중심점을 계산\n",
    "    pred_xy = (tf.sigmoid(conv_raw_dxdy) + xy_grid) * STRIDES[i]\n",
    "    # 상자의 너비와 높이를 계산\n",
    "    pred_wh = (tf.exp(conv_raw_dwdh) * ANCHORS[i]) * STRIDES[i]\n",
    "\n",
    "    pred_xywh = tf.concat([pred_xy, pred_wh], axis=-1)\n",
    "    pred_conf = tf.sigmoid(conv_raw_conf) # 상자의 신뢰도 계산\n",
    "    pred_prob = tf.sigmoid(conv_raw_prob) # 클래스별 확률 계산\n",
    "\n",
    "    return tf.concat([pred_xywh, pred_conf, pred_prob], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e59f568",
   "metadata": {},
   "source": [
    "## YOLOv3 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7f1cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_YOLOv3(num_class, input_shape=(416,416,3), train_mode=False):\n",
    "    input_layer  = layers.Input(input_shape)\n",
    "    conv_tensors = YOLOv3(input_layer, num_class)\n",
    "    output_tensors = []\n",
    "    for i, conv_tensor in enumerate(conv_tensors):\n",
    "        pred_tensor = decode(conv_tensor, num_class, i)\n",
    "        if train_mode: output_tensors.append(conv_tensor)\n",
    "        output_tensors.append(pred_tensor)\n",
    "\n",
    "    model = tf.keras.Model(input_layer, output_tensors)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b42f66d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-20 18:23:43.454602: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 416, 416, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 416, 416, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 416, 416, 32  128        ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " elu (ELU)                      (None, 416, 416, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 417, 417, 32  0          ['elu[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 208, 208, 64  18432       ['zero_padding2d[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 208, 208, 64  256        ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " elu_1 (ELU)                    (None, 208, 208, 64  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 208, 208, 32  2048        ['elu_1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 208, 208, 32  128        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " elu_2 (ELU)                    (None, 208, 208, 32  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 208, 208, 64  18432       ['elu_2[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 208, 208, 64  256        ['conv2d_3[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " elu_3 (ELU)                    (None, 208, 208, 64  0           ['batch_normalization_3[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 208, 208, 64  0          ['elu_1[0][0]',                  \n",
      " da)                            )                                 'elu_3[0][0]']                  \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadding2  (None, 209, 209, 64  0          ['tf.__operators__.add[0][0]']   \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 104, 104, 12  73728       ['zero_padding2d_1[0][0]']       \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 104, 104, 12  512        ['conv2d_4[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " elu_4 (ELU)                    (None, 104, 104, 12  0           ['batch_normalization_4[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 104, 104, 64  8192        ['elu_4[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 104, 104, 64  256        ['conv2d_5[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " elu_5 (ELU)                    (None, 104, 104, 64  0           ['batch_normalization_5[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 104, 104, 12  73728       ['elu_5[0][0]']                  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 104, 104, 12  512        ['conv2d_6[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " elu_6 (ELU)                    (None, 104, 104, 12  0           ['batch_normalization_6[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 104, 104, 12  0          ['elu_4[0][0]',                  \n",
      " mbda)                          8)                                'elu_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 104, 104, 64  8192        ['tf.__operators__.add_1[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 104, 104, 64  256        ['conv2d_7[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " elu_7 (ELU)                    (None, 104, 104, 64  0           ['batch_normalization_7[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 104, 104, 12  73728       ['elu_7[0][0]']                  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 104, 104, 12  512        ['conv2d_8[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " elu_8 (ELU)                    (None, 104, 104, 12  0           ['batch_normalization_8[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 104, 104, 12  0          ['tf.__operators__.add_1[0][0]', \n",
      " mbda)                          8)                                'elu_8[0][0]']                  \n",
      "                                                                                                  \n",
      " zero_padding2d_2 (ZeroPadding2  (None, 105, 105, 12  0          ['tf.__operators__.add_2[0][0]'] \n",
      " D)                             8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 52, 52, 256)  294912      ['zero_padding2d_2[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 52, 52, 256)  1024       ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " elu_9 (ELU)                    (None, 52, 52, 256)  0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 52, 52, 128)  32768       ['elu_9[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 52, 52, 128)  512        ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_10 (ELU)                   (None, 52, 52, 128)  0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 52, 52, 256)  294912      ['elu_10[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 52, 52, 256)  1024       ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_11 (ELU)                   (None, 52, 52, 256)  0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 52, 52, 256)  0          ['elu_9[0][0]',                  \n",
      " mbda)                                                            'elu_11[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 52, 52, 128)  32768       ['tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 52, 52, 128)  512        ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_12 (ELU)                   (None, 52, 52, 128)  0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 52, 52, 256)  294912      ['elu_12[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 52, 52, 256)  1024       ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_13 (ELU)                   (None, 52, 52, 256)  0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 52, 52, 256)  0          ['tf.__operators__.add_3[0][0]', \n",
      " mbda)                                                            'elu_13[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 52, 52, 128)  32768       ['tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 52, 52, 128)  512        ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_14 (ELU)                   (None, 52, 52, 128)  0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 52, 52, 256)  294912      ['elu_14[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 52, 52, 256)  1024       ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_15 (ELU)                   (None, 52, 52, 256)  0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 52, 52, 256)  0          ['tf.__operators__.add_4[0][0]', \n",
      " mbda)                                                            'elu_15[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 52, 52, 128)  32768       ['tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 52, 52, 128)  512        ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_16 (ELU)                   (None, 52, 52, 128)  0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 52, 52, 256)  294912      ['elu_16[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 52, 52, 256)  1024       ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_17 (ELU)                   (None, 52, 52, 256)  0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 52, 52, 256)  0          ['tf.__operators__.add_5[0][0]', \n",
      " mbda)                                                            'elu_17[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 52, 52, 128)  32768       ['tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 52, 52, 128)  512        ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_18 (ELU)                   (None, 52, 52, 128)  0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 52, 52, 256)  294912      ['elu_18[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 52, 52, 256)  1024       ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_19 (ELU)                   (None, 52, 52, 256)  0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 52, 52, 256)  0          ['tf.__operators__.add_6[0][0]', \n",
      " mbda)                                                            'elu_19[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 52, 52, 128)  32768       ['tf.__operators__.add_7[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 52, 52, 128)  512        ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_20 (ELU)                   (None, 52, 52, 128)  0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 52, 52, 256)  294912      ['elu_20[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 52, 52, 256)  1024       ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_21 (ELU)                   (None, 52, 52, 256)  0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TFOpLa  (None, 52, 52, 256)  0          ['tf.__operators__.add_7[0][0]', \n",
      " mbda)                                                            'elu_21[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 52, 52, 128)  32768       ['tf.__operators__.add_8[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 52, 52, 128)  512        ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_22 (ELU)                   (None, 52, 52, 128)  0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 52, 52, 256)  294912      ['elu_22[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 52, 52, 256)  1024       ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_23 (ELU)                   (None, 52, 52, 256)  0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_9 (TFOpLa  (None, 52, 52, 256)  0          ['tf.__operators__.add_8[0][0]', \n",
      " mbda)                                                            'elu_23[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 52, 52, 128)  32768       ['tf.__operators__.add_9[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 52, 52, 128)  512        ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_24 (ELU)                   (None, 52, 52, 128)  0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 52, 52, 256)  294912      ['elu_24[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 52, 52, 256)  1024       ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_25 (ELU)                   (None, 52, 52, 256)  0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_10 (TFOpL  (None, 52, 52, 256)  0          ['tf.__operators__.add_9[0][0]', \n",
      " ambda)                                                           'elu_25[0][0]']                 \n",
      "                                                                                                  \n",
      " zero_padding2d_3 (ZeroPadding2  (None, 53, 53, 256)  0          ['tf.__operators__.add_10[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 26, 26, 512)  1179648     ['zero_padding2d_3[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 26, 26, 512)  2048       ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_26 (ELU)                   (None, 26, 26, 512)  0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 26, 26, 256)  131072      ['elu_26[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 26, 26, 256)  1024       ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_27 (ELU)                   (None, 26, 26, 256)  0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 26, 26, 512)  1179648     ['elu_27[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 26, 26, 512)  2048       ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_28 (ELU)                   (None, 26, 26, 512)  0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_11 (TFOpL  (None, 26, 26, 512)  0          ['elu_26[0][0]',                 \n",
      " ambda)                                                           'elu_28[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 26, 26, 256)  131072      ['tf.__operators__.add_11[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 26, 26, 256)  1024       ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_29 (ELU)                   (None, 26, 26, 256)  0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 26, 26, 512)  1179648     ['elu_29[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 26, 26, 512)  2048       ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_30 (ELU)                   (None, 26, 26, 512)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_12 (TFOpL  (None, 26, 26, 512)  0          ['tf.__operators__.add_11[0][0]',\n",
      " ambda)                                                           'elu_30[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 26, 26, 256)  131072      ['tf.__operators__.add_12[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 26, 26, 256)  1024       ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_31 (ELU)                   (None, 26, 26, 256)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 26, 26, 512)  1179648     ['elu_31[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 26, 26, 512)  2048       ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_32 (ELU)                   (None, 26, 26, 512)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_13 (TFOpL  (None, 26, 26, 512)  0          ['tf.__operators__.add_12[0][0]',\n",
      " ambda)                                                           'elu_32[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 26, 26, 256)  131072      ['tf.__operators__.add_13[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 26, 26, 256)  1024       ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_33 (ELU)                   (None, 26, 26, 256)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 26, 26, 512)  1179648     ['elu_33[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 26, 26, 512)  2048       ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_34 (ELU)                   (None, 26, 26, 512)  0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_14 (TFOpL  (None, 26, 26, 512)  0          ['tf.__operators__.add_13[0][0]',\n",
      " ambda)                                                           'elu_34[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 26, 26, 256)  131072      ['tf.__operators__.add_14[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 26, 26, 256)  1024       ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_35 (ELU)                   (None, 26, 26, 256)  0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 26, 26, 512)  1179648     ['elu_35[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 26, 26, 512)  2048       ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_36 (ELU)                   (None, 26, 26, 512)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_15 (TFOpL  (None, 26, 26, 512)  0          ['tf.__operators__.add_14[0][0]',\n",
      " ambda)                                                           'elu_36[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 26, 26, 256)  131072      ['tf.__operators__.add_15[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 26, 26, 256)  1024       ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_37 (ELU)                   (None, 26, 26, 256)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 26, 26, 512)  1179648     ['elu_37[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 26, 26, 512)  2048       ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_38 (ELU)                   (None, 26, 26, 512)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_16 (TFOpL  (None, 26, 26, 512)  0          ['tf.__operators__.add_15[0][0]',\n",
      " ambda)                                                           'elu_38[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 26, 26, 256)  131072      ['tf.__operators__.add_16[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 26, 26, 256)  1024       ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_39 (ELU)                   (None, 26, 26, 256)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 26, 26, 512)  1179648     ['elu_39[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 26, 26, 512)  2048       ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_40 (ELU)                   (None, 26, 26, 512)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_17 (TFOpL  (None, 26, 26, 512)  0          ['tf.__operators__.add_16[0][0]',\n",
      " ambda)                                                           'elu_40[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 26, 26, 256)  131072      ['tf.__operators__.add_17[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 26, 26, 256)  1024       ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_41 (ELU)                   (None, 26, 26, 256)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 26, 26, 512)  1179648     ['elu_41[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 26, 26, 512)  2048       ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_42 (ELU)                   (None, 26, 26, 512)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_18 (TFOpL  (None, 26, 26, 512)  0          ['tf.__operators__.add_17[0][0]',\n",
      " ambda)                                                           'elu_42[0][0]']                 \n",
      "                                                                                                  \n",
      " zero_padding2d_4 (ZeroPadding2  (None, 27, 27, 512)  0          ['tf.__operators__.add_18[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 13, 13, 1024  4718592     ['zero_padding2d_4[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 13, 13, 1024  4096       ['conv2d_43[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " elu_43 (ELU)                   (None, 13, 13, 1024  0           ['batch_normalization_43[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 13, 13, 512)  524288      ['elu_43[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 13, 13, 512)  2048       ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_44 (ELU)                   (None, 13, 13, 512)  0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 13, 13, 1024  4718592     ['elu_44[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 13, 13, 1024  4096       ['conv2d_45[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " elu_45 (ELU)                   (None, 13, 13, 1024  0           ['batch_normalization_45[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add_19 (TFOpL  (None, 13, 13, 1024  0          ['elu_43[0][0]',                 \n",
      " ambda)                         )                                 'elu_45[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 13, 13, 512)  524288      ['tf.__operators__.add_19[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 13, 13, 512)  2048       ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_46 (ELU)                   (None, 13, 13, 512)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 13, 13, 1024  4718592     ['elu_46[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 13, 13, 1024  4096       ['conv2d_47[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " elu_47 (ELU)                   (None, 13, 13, 1024  0           ['batch_normalization_47[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add_20 (TFOpL  (None, 13, 13, 1024  0          ['tf.__operators__.add_19[0][0]',\n",
      " ambda)                         )                                 'elu_47[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 13, 13, 512)  524288      ['tf.__operators__.add_20[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 13, 13, 512)  2048       ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_48 (ELU)                   (None, 13, 13, 512)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 13, 13, 1024  4718592     ['elu_48[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 13, 13, 1024  4096       ['conv2d_49[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " elu_49 (ELU)                   (None, 13, 13, 1024  0           ['batch_normalization_49[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add_21 (TFOpL  (None, 13, 13, 1024  0          ['tf.__operators__.add_20[0][0]',\n",
      " ambda)                         )                                 'elu_49[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 13, 13, 512)  524288      ['tf.__operators__.add_21[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 13, 13, 512)  2048       ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_50 (ELU)                   (None, 13, 13, 512)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 13, 13, 1024  4718592     ['elu_50[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 13, 13, 1024  4096       ['conv2d_51[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " elu_51 (ELU)                   (None, 13, 13, 1024  0           ['batch_normalization_51[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add_22 (TFOpL  (None, 13, 13, 1024  0          ['tf.__operators__.add_21[0][0]',\n",
      " ambda)                         )                                 'elu_51[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 13, 13, 512)  524288      ['tf.__operators__.add_22[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 13, 13, 512)  2048       ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_52 (ELU)                   (None, 13, 13, 512)  0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 13, 13, 1024  4718592     ['elu_52[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 13, 13, 1024  4096       ['conv2d_53[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " elu_53 (ELU)                   (None, 13, 13, 1024  0           ['batch_normalization_53[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 13, 13, 512)  524288      ['elu_53[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 13, 13, 512)  2048       ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_54 (ELU)                   (None, 13, 13, 512)  0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 13, 13, 1024  4718592     ['elu_54[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 13, 13, 1024  4096       ['conv2d_55[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " elu_55 (ELU)                   (None, 13, 13, 1024  0           ['batch_normalization_55[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 13, 13, 512)  524288      ['elu_55[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 13, 13, 512)  2048       ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_56 (ELU)                   (None, 13, 13, 512)  0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 13, 13, 256)  131072      ['elu_56[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 13, 13, 256)  1024       ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_58 (ELU)                   (None, 13, 13, 256)  0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " tf.image.resize (TFOpLambda)   (None, 26, 26, 256)  0           ['elu_58[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 26, 26, 768)  0           ['tf.image.resize[0][0]',        \n",
      "                                                                  'tf.__operators__.add_18[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 26, 26, 256)  196608      ['tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 26, 26, 256)  1024       ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_59 (ELU)                   (None, 26, 26, 256)  0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 26, 26, 512)  1179648     ['elu_59[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 26, 26, 512)  2048       ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_60 (ELU)                   (None, 26, 26, 512)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 26, 26, 256)  131072      ['elu_60[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 26, 26, 256)  1024       ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_61 (ELU)                   (None, 26, 26, 256)  0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 26, 26, 512)  1179648     ['elu_61[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 26, 26, 512)  2048       ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_62 (ELU)                   (None, 26, 26, 512)  0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 26, 26, 256)  131072      ['elu_62[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 26, 26, 256)  1024       ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_63 (ELU)                   (None, 26, 26, 256)  0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 26, 26, 128)  32768       ['elu_63[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 26, 26, 128)  512        ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_65 (ELU)                   (None, 26, 26, 128)  0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " tf.image.resize_1 (TFOpLambda)  (None, 52, 52, 128)  0          ['elu_65[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)       (None, 52, 52, 384)  0           ['tf.image.resize_1[0][0]',      \n",
      "                                                                  'tf.__operators__.add_10[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 52, 52, 128)  49152       ['tf.concat_1[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 52, 52, 128)  512        ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_66 (ELU)                   (None, 52, 52, 128)  0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 52, 52, 256)  294912      ['elu_66[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 52, 52, 256)  1024       ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_67 (ELU)                   (None, 52, 52, 256)  0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 52, 52, 128)  32768       ['elu_67[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 52, 52, 128)  512        ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_68 (ELU)                   (None, 52, 52, 128)  0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 52, 52, 256)  294912      ['elu_68[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 52, 52, 256)  1024       ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_69 (ELU)                   (None, 52, 52, 256)  0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 52, 52, 128)  32768       ['elu_69[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 52, 52, 128)  512        ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " elu_70 (ELU)                   (None, 52, 52, 128)  0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 52, 52, 256)  294912      ['elu_70[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 26, 26, 512)  1179648     ['elu_63[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 13, 13, 1024  4718592     ['elu_56[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 52, 52, 256)  1024       ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 26, 26, 512)  2048       ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 13, 13, 1024  4096       ['conv2d_57[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " elu_71 (ELU)                   (None, 52, 52, 256)  0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " elu_64 (ELU)                   (None, 26, 26, 512)  0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " elu_57 (ELU)                   (None, 13, 13, 1024  0           ['batch_normalization_57[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 52, 52, 45)   11565       ['elu_71[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 26, 26, 45)   23085       ['elu_64[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 13, 13, 45)   46125       ['elu_57[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape (TFOpLambda  (4,)                0           ['conv2d_74[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_1 (TFOpLamb  (4,)                0           ['conv2d_66[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_2 (TFOpLamb  (4,)                0           ['conv2d_58[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  ()                  0           ['tf.compat.v1.shape[0][0]']     \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_10 (S  ()                  0           ['tf.compat.v1.shape_1[0][0]']   \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_19 (S  ()                  0           ['tf.compat.v1.shape_2[0][0]']   \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.range_1 (TFOpLambda)        (52,)                0           ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.range (TFOpLambda)          (52,)                0           ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.range_3 (TFOpLambda)        (26,)                0           ['tf.__operators__.getitem_10[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.range_2 (TFOpLambda)        (26,)                0           ['tf.__operators__.getitem_10[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.range_5 (TFOpLambda)        (13,)                0           ['tf.__operators__.getitem_19[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.range_4 (TFOpLambda)        (13,)                0           ['tf.__operators__.getitem_19[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_1 (TFOpLambda)  (1, 52)              0           ['tf.range_1[0][0]']             \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (52, 1)              0           ['tf.range[0][0]']               \n",
      "                                                                                                  \n",
      " tf.expand_dims_3 (TFOpLambda)  (1, 26)              0           ['tf.range_3[0][0]']             \n",
      "                                                                                                  \n",
      " tf.expand_dims_2 (TFOpLambda)  (26, 1)              0           ['tf.range_2[0][0]']             \n",
      "                                                                                                  \n",
      " tf.expand_dims_5 (TFOpLambda)  (1, 13)              0           ['tf.range_5[0][0]']             \n",
      "                                                                                                  \n",
      " tf.expand_dims_4 (TFOpLambda)  (13, 1)              0           ['tf.range_4[0][0]']             \n",
      "                                                                                                  \n",
      " tf.tile_1 (TFOpLambda)         (52, 52)             0           ['tf.expand_dims_1[0][0]',       \n",
      "                                                                  'tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.tile (TFOpLambda)           (52, 52)             0           ['tf.expand_dims[0][0]',         \n",
      "                                                                  'tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.tile_4 (TFOpLambda)         (26, 26)             0           ['tf.expand_dims_3[0][0]',       \n",
      "                                                                  'tf.__operators__.getitem_10[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.tile_3 (TFOpLambda)         (26, 26)             0           ['tf.expand_dims_2[0][0]',       \n",
      "                                                                  'tf.__operators__.getitem_10[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.tile_7 (TFOpLambda)         (13, 13)             0           ['tf.expand_dims_5[0][0]',       \n",
      "                                                                  'tf.__operators__.getitem_19[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.tile_6 (TFOpLambda)         (13, 13)             0           ['tf.expand_dims_4[0][0]',       \n",
      "                                                                  'tf.__operators__.getitem_19[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_6 (Sl  (52, 52, 1)         0           ['tf.tile_1[0][0]']              \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_7 (Sl  (52, 52, 1)         0           ['tf.tile[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_15 (S  (26, 26, 1)         0           ['tf.tile_4[0][0]']              \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_16 (S  (26, 26, 1)         0           ['tf.tile_3[0][0]']              \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_24 (S  (13, 13, 1)         0           ['tf.tile_7[0][0]']              \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_25 (S  (13, 13, 1)         0           ['tf.tile_6[0][0]']              \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  ()                  0           ['tf.compat.v1.shape[0][0]']     \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.concat_2 (TFOpLambda)       (52, 52, 2)          0           ['tf.__operators__.getitem_6[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'tf.__operators__.getitem_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_9 (Sl  ()                  0           ['tf.compat.v1.shape_1[0][0]']   \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.concat_5 (TFOpLambda)       (26, 26, 2)          0           ['tf.__operators__.getitem_15[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_16[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_18 (S  ()                  0           ['tf.compat.v1.shape_2[0][0]']   \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.concat_8 (TFOpLambda)       (13, 13, 2)          0           ['tf.__operators__.getitem_24[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_25[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)        (None, 52, 52, 3, 1  0           ['conv2d_74[0][0]',              \n",
      "                                5)                                'tf.__operators__.getitem[0][0]'\n",
      "                                                                 , 'tf.__operators__.getitem_1[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_8 (Sl  (1, 52, 52, 1, 2)   0           ['tf.concat_2[0][0]']            \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.reshape_1 (TFOpLambda)      (None, 26, 26, 3, 1  0           ['conv2d_66[0][0]',              \n",
      "                                5)                                'tf.__operators__.getitem_9[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'tf.__operators__.getitem_10[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_10[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_17 (S  (1, 26, 26, 1, 2)   0           ['tf.concat_5[0][0]']            \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.reshape_2 (TFOpLambda)      (None, 13, 13, 3, 1  0           ['conv2d_58[0][0]',              \n",
      "                                5)                                'tf.__operators__.getitem_18[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_19[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_19[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_26 (S  (1, 13, 13, 1, 2)   0           ['tf.concat_8[0][0]']            \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  (None, 52, 52, 3, 2  0          ['tf.reshape[0][0]']             \n",
      " icingOpLambda)                 )                                                                 \n",
      "                                                                                                  \n",
      " tf.tile_2 (TFOpLambda)         (None, 52, 52, 3, 2  0           ['tf.__operators__.getitem_8[0][0\n",
      "                                )                                ]',                              \n",
      "                                                                  'tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3 (Sl  (None, 52, 52, 3, 2  0          ['tf.reshape[0][0]']             \n",
      " icingOpLambda)                 )                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_11 (S  (None, 26, 26, 3, 2  0          ['tf.reshape_1[0][0]']           \n",
      " licingOpLambda)                )                                                                 \n",
      "                                                                                                  \n",
      " tf.tile_5 (TFOpLambda)         (None, 26, 26, 3, 2  0           ['tf.__operators__.getitem_17[0][\n",
      "                                )                                0]',                             \n",
      "                                                                  'tf.__operators__.getitem_9[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_12 (S  (None, 26, 26, 3, 2  0          ['tf.reshape_1[0][0]']           \n",
      " licingOpLambda)                )                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_20 (S  (None, 13, 13, 3, 2  0          ['tf.reshape_2[0][0]']           \n",
      " licingOpLambda)                )                                                                 \n",
      "                                                                                                  \n",
      " tf.tile_8 (TFOpLambda)         (None, 13, 13, 3, 2  0           ['tf.__operators__.getitem_26[0][\n",
      "                                )                                0]',                             \n",
      "                                                                  'tf.__operators__.getitem_18[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_21 (S  (None, 13, 13, 3, 2  0          ['tf.reshape_2[0][0]']           \n",
      " licingOpLambda)                )                                                                 \n",
      "                                                                                                  \n",
      " tf.math.sigmoid (TFOpLambda)   (None, 52, 52, 3, 2  0           ['tf.__operators__.getitem_2[0][0\n",
      "                                )                                ]']                              \n",
      "                                                                                                  \n",
      " tf.cast (TFOpLambda)           (None, 52, 52, 3, 2  0           ['tf.tile_2[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.math.exp (TFOpLambda)       (None, 52, 52, 3, 2  0           ['tf.__operators__.getitem_3[0][0\n",
      "                                )                                ]']                              \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_3 (TFOpLambda)  (None, 26, 26, 3, 2  0          ['tf.__operators__.getitem_11[0][\n",
      "                                )                                0]']                             \n",
      "                                                                                                  \n",
      " tf.cast_1 (TFOpLambda)         (None, 26, 26, 3, 2  0           ['tf.tile_5[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.math.exp_1 (TFOpLambda)     (None, 26, 26, 3, 2  0           ['tf.__operators__.getitem_12[0][\n",
      "                                )                                0]']                             \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_6 (TFOpLambda)  (None, 13, 13, 3, 2  0          ['tf.__operators__.getitem_20[0][\n",
      "                                )                                0]']                             \n",
      "                                                                                                  \n",
      " tf.cast_2 (TFOpLambda)         (None, 13, 13, 3, 2  0           ['tf.tile_8[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.math.exp_2 (TFOpLambda)     (None, 13, 13, 3, 2  0           ['tf.__operators__.getitem_21[0][\n",
      "                                )                                0]']                             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_23 (TFOpL  (None, 52, 52, 3, 2  0          ['tf.math.sigmoid[0][0]',        \n",
      " ambda)                         )                                 'tf.cast[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None, 52, 52, 3, 2  0          ['tf.math.exp[0][0]']            \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add_24 (TFOpL  (None, 26, 26, 3, 2  0          ['tf.math.sigmoid_3[0][0]',      \n",
      " ambda)                         )                                 'tf.cast_1[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLambda  (None, 26, 26, 3, 2  0          ['tf.math.exp_1[0][0]']          \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add_25 (TFOpL  (None, 13, 13, 3, 2  0          ['tf.math.sigmoid_6[0][0]',      \n",
      " ambda)                         )                                 'tf.cast_2[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.multiply_7 (TFOpLambda  (None, 13, 13, 3, 2  0          ['tf.math.exp_2[0][0]']          \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 52, 52, 3, 2  0           ['tf.__operators__.add_23[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLambda  (None, 52, 52, 3, 2  0          ['tf.math.multiply_1[0][0]']     \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4 (Sl  (None, 52, 52, 3, 1  0          ['tf.reshape[0][0]']             \n",
      " icingOpLambda)                 )                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_5 (Sl  (None, 52, 52, 3, 1  0          ['tf.reshape[0][0]']             \n",
      " icingOpLambda)                 0)                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLambda  (None, 26, 26, 3, 2  0          ['tf.__operators__.add_24[0][0]']\n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLambda  (None, 26, 26, 3, 2  0          ['tf.math.multiply_4[0][0]']     \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_13 (S  (None, 26, 26, 3, 1  0          ['tf.reshape_1[0][0]']           \n",
      " licingOpLambda)                )                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_14 (S  (None, 26, 26, 3, 1  0          ['tf.reshape_1[0][0]']           \n",
      " licingOpLambda)                0)                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLambda  (None, 13, 13, 3, 2  0          ['tf.__operators__.add_25[0][0]']\n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " tf.math.multiply_8 (TFOpLambda  (None, 13, 13, 3, 2  0          ['tf.math.multiply_7[0][0]']     \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_22 (S  (None, 13, 13, 3, 1  0          ['tf.reshape_2[0][0]']           \n",
      " licingOpLambda)                )                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_23 (S  (None, 13, 13, 3, 1  0          ['tf.reshape_2[0][0]']           \n",
      " licingOpLambda)                0)                                                                \n",
      "                                                                                                  \n",
      " tf.concat_3 (TFOpLambda)       (None, 52, 52, 3, 4  0           ['tf.math.multiply[0][0]',       \n",
      "                                )                                 'tf.math.multiply_2[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_1 (TFOpLambda)  (None, 52, 52, 3, 1  0          ['tf.__operators__.getitem_4[0][0\n",
      "                                )                                ]']                              \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_2 (TFOpLambda)  (None, 52, 52, 3, 1  0          ['tf.__operators__.getitem_5[0][0\n",
      "                                0)                               ]']                              \n",
      "                                                                                                  \n",
      " tf.concat_6 (TFOpLambda)       (None, 26, 26, 3, 4  0           ['tf.math.multiply_3[0][0]',     \n",
      "                                )                                 'tf.math.multiply_5[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_4 (TFOpLambda)  (None, 26, 26, 3, 1  0          ['tf.__operators__.getitem_13[0][\n",
      "                                )                                0]']                             \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_5 (TFOpLambda)  (None, 26, 26, 3, 1  0          ['tf.__operators__.getitem_14[0][\n",
      "                                0)                               0]']                             \n",
      "                                                                                                  \n",
      " tf.concat_9 (TFOpLambda)       (None, 13, 13, 3, 4  0           ['tf.math.multiply_6[0][0]',     \n",
      "                                )                                 'tf.math.multiply_8[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_7 (TFOpLambda)  (None, 13, 13, 3, 1  0          ['tf.__operators__.getitem_22[0][\n",
      "                                )                                0]']                             \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_8 (TFOpLambda)  (None, 13, 13, 3, 1  0          ['tf.__operators__.getitem_23[0][\n",
      "                                0)                               0]']                             \n",
      "                                                                                                  \n",
      " tf.concat_4 (TFOpLambda)       (None, 52, 52, 3, 1  0           ['tf.concat_3[0][0]',            \n",
      "                                5)                                'tf.math.sigmoid_1[0][0]',      \n",
      "                                                                  'tf.math.sigmoid_2[0][0]']      \n",
      "                                                                                                  \n",
      " tf.concat_7 (TFOpLambda)       (None, 26, 26, 3, 1  0           ['tf.concat_6[0][0]',            \n",
      "                                5)                                'tf.math.sigmoid_4[0][0]',      \n",
      "                                                                  'tf.math.sigmoid_5[0][0]']      \n",
      "                                                                                                  \n",
      " tf.concat_10 (TFOpLambda)      (None, 13, 13, 3, 1  0           ['tf.concat_9[0][0]',            \n",
      "                                5)                                'tf.math.sigmoid_7[0][0]',      \n",
      "                                                                  'tf.math.sigmoid_8[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 61,624,807\n",
      "Trainable params: 61,572,199\n",
      "Non-trainable params: 52,608\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASS = 10\n",
    "yolo = Create_YOLOv3(train_mode=True, num_class=NUM_CLASS)\n",
    "yolo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fcb80a",
   "metadata": {},
   "source": [
    "# 모델 만들고 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8450609b",
   "metadata": {},
   "source": [
    "## 이미지 전처리하기(image_process.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e0b0b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "# 이미지를 정사각형 크기로 변환, \n",
    "# 채워지는 화소 기본값은 value속성의 값으로 설정함\n",
    "def resize_to_square(image, target_size, gt_boxes=None, value=128.0):\n",
    "    ih, iw = target_size, target_size\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    scale = min(iw / w, ih / h)\n",
    "    nw, nh = int(scale * w), int(scale * h)\n",
    "    image_resized = cv2.resize(image, (nw, nh))\n",
    "\n",
    "    image_padded = np.full(shape=[ih, iw, 3], fill_value=value)\n",
    "    dw, dh = (iw - nw) // 2, (ih - nh) // 2\n",
    "    image_padded[dh:nh + dh, dw:nw + dw, :] = image_resized\n",
    "    image_padded = image_padded / 255.\n",
    "\n",
    "    if gt_boxes is None:\n",
    "        return image_padded\n",
    "    else:\n",
    "        gt_boxes[:, [0, 2]] = gt_boxes[:, [0, 2]] * scale + dw\n",
    "        gt_boxes[:, [1, 3]] = gt_boxes[:, [1, 3]] * scale + dh\n",
    "        return image_padded, gt_boxes\n",
    "    \n",
    "\n",
    "def random_horizontal_flip(image, bboxes, p=0.5):\n",
    "    if random.random() < p:\n",
    "        _, w, _ = image.shape\n",
    "        image = image[:, ::-1, :]\n",
    "        bboxes[:, [0, 2]] = w - bboxes[:, [2, 0]]\n",
    "\n",
    "    return image, bboxes\n",
    "\n",
    "# 자르기 \n",
    "def random_crop(image, bboxes, p=0.5):\n",
    "    if random.random() < p:\n",
    "        h, w, _ = image.shape\n",
    "        max_bbox = np.concatenate( \n",
    "            [np.min(bboxes[:, 0:2], axis=0), \n",
    "             np.max(bboxes[:, 2:4], axis=0)], axis=-1)\n",
    "\n",
    "        max_l_trans = max_bbox[0]\n",
    "        max_u_trans = max_bbox[1]\n",
    "        max_r_trans = w - max_bbox[2]\n",
    "        max_d_trans = h - max_bbox[3]\n",
    "\n",
    "        crop_xmin = max(0, int(max_bbox[0] - random.uniform(0, max_l_trans)))\n",
    "        crop_ymin = max(0, int(max_bbox[1] - random.uniform(0, max_u_trans)))\n",
    "        crop_xmax = max(w, int(max_bbox[2] + random.uniform(0, max_r_trans)))\n",
    "        crop_ymax = max(h, int(max_bbox[3] + random.uniform(0, max_d_trans)))\n",
    "\n",
    "        image = image[crop_ymin:crop_ymax, crop_xmin:crop_xmax]\n",
    "\n",
    "        bboxes[:, [0, 2]] = bboxes[:, [0, 2]] - crop_xmin\n",
    "        bboxes[:, [1, 3]] = bboxes[:, [1, 3]] - crop_ymin\n",
    "  \n",
    "    return image, bboxes\n",
    "\n",
    "  \n",
    "# 이동 \n",
    "def random_translate(image, bboxes, p=0.5):\n",
    "    if random.random() < p:\n",
    "        h, w, _ = image.shape\n",
    "        max_bbox = np.concatenate( \n",
    "            [np.min(bboxes[:, 0:2], axis=0),\n",
    "             np.max(bboxes[:, 2:4], axis=0)], axis=-1)\n",
    "\n",
    "        max_l_trans = max_bbox[0]\n",
    "        max_u_trans = max_bbox[1]\n",
    "        max_r_trans = w - max_bbox[2]\n",
    "        max_d_trans = h - max_bbox[3]\n",
    "\n",
    "        tx = random.uniform(-(max_l_trans-1), (max_r_trans-1))\n",
    "        ty = random.uniform(-(max_u_trans-1), (max_d_trans-1))\n",
    "\n",
    "        M = np.array([[1, 0, tx], [0, 1, ty]])\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "\n",
    "        bboxes[:, [0, 2]] = bboxes[:, [0, 2]] + tx\n",
    "        bboxes[:, [1, 3]] = bboxes[:, [1, 3]] + ty\n",
    "\n",
    "    return image, bboxes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938d2db6",
   "metadata": {},
   "source": [
    "## IoU 계산하기(bbox_iou.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "651b1e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def bbox_iou(boxes1, boxes2):\n",
    "    boxes1_area = boxes1[..., 2] * boxes1[..., 3]\n",
    "    boxes2_area = boxes2[..., 2] * boxes2[..., 3]\n",
    "\n",
    "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5, \n",
    "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5],\n",
    "                       axis=-1)\n",
    "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5, \n",
    "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5],\n",
    "                       axis=-1)\n",
    "\n",
    "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "\n",
    "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
    "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area = boxes1_area + boxes2_area - inter_area\n",
    "\n",
    "    return 1.0 * inter_area / union_area\n",
    " \n",
    "# GIoU 계산하는 함수 \n",
    "def bbox_giou(boxes1, boxes2):\n",
    "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
    "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5],\n",
    "                       axis=-1)\n",
    "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
    "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5],\n",
    "                       axis=-1)\n",
    "\n",
    "    boxes1 = tf.concat([tf.minimum(boxes1[...,:2], boxes1[...,2:]),\n",
    "                        tf.maximum(boxes1[...,:2], boxes1[...,2:])], \n",
    "                       axis=-1)\n",
    "    boxes2 = tf.concat([tf.minimum(boxes2[...,:2], boxes2[...,2:]),\n",
    "                        tf.maximum(boxes2[...,:2], boxes2[...,2:])],\n",
    "                       axis=-1)\n",
    "\n",
    "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
    "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
    "\n",
    "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "\n",
    "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
    "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area = boxes1_area + boxes2_area - inter_area\n",
    "  \n",
    "    # 두 경계 상자의 IoU를 계산 \n",
    "    iou = inter_area / union_area\n",
    "\n",
    "    # 왼쪽 위와 오른쪽 아래를 포함하는 가장 작은 사각형 계산 \n",
    "    enclose_left_up = tf.minimum(boxes1[..., :2], boxes2[..., :2])\n",
    "    enclose_right_down = tf.maximum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "    enclose = tf.maximum(enclose_right_down - enclose_left_up, 0.0)\n",
    "  \n",
    "    # 가장 작은 C 상자의 면적 계산 \n",
    "    enclose_area = enclose[..., 0] * enclose[..., 1]\n",
    "  \n",
    "    # GIoU 공식으로 GIoU 계산 \n",
    "    giou = iou - 1.0 * (enclose_area - union_area) / enclose_area\n",
    "\n",
    "    return giou\n",
    " \n",
    "# CIoU 계산하는 함수 \n",
    "def bbox_ciou(boxes1, boxes2):\n",
    "    boxes1_coor = tf.concat([boxes1[...,:2] - boxes1[...,2:] * 0.5, \n",
    "                             boxes1[...,:2] + boxes1[...,2:] * 0.5], \n",
    "                            axis=-1)\n",
    "    boxes2_coor = tf.concat([boxes2[...,:2] - boxes2[...,2:] * 0.5, \n",
    "                             boxes2[...,:2] + boxes2[...,2:] * 0.5], \n",
    "                            axis=-1)\n",
    "\n",
    "    left = tf.maximum(boxes1_coor[..., 0], boxes2_coor[..., 0])\n",
    "    up = tf.maximum(boxes1_coor[..., 1], boxes2_coor[..., 1])\n",
    "    right = tf.maximum(boxes1_coor[..., 2], boxes2_coor[..., 2])\n",
    "    down = tf.maximum(boxes1_coor[..., 3], boxes2_coor[..., 3])\n",
    "\n",
    "    c = (right - left) * (right - left) + (up - down) * (up - down)\n",
    "    iou = bbox_iou(boxes1, boxes2)\n",
    "\n",
    "    u = (boxes1[..., 0] - boxes2[..., 0]) * (boxes1[..., 0] - boxes2[..., 0]) + (boxes1[..., 1] - boxes2[..., 1]) * (boxes1[..., 1] - boxes2[..., 1])\n",
    "    d = u / c\n",
    "\n",
    "    ar_gt = boxes2[..., 2] / boxes2[..., 3]\n",
    "    ar_pred = boxes1[..., 2] / boxes1[..., 3]\n",
    "\n",
    "    ar_loss = 4 / (np.pi * np.pi) * (tf.atan(ar_gt) - tf.atan(ar_pred)) * (tf.atan(ar_gt) - tf.atan(ar_pred))\n",
    "    alpha = ar_loss / (1 - iou + ar_loss + 0.000001)\n",
    "    ciou_term = d + alpha * ar_loss\n",
    " \n",
    "    return iou - ciou_term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0a2372",
   "metadata": {},
   "source": [
    "## 스트라이드와 앵커박스(config.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc780c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "YOLO_STRIDES  = [8, 16, 32]\n",
    "YOLO_ANCHORS  = [[[10,  13], [16,   30], [33,   23]],\n",
    "                 [[30,  61], [62,   45], [59,  119]],\n",
    "                 [[116, 90], [156, 198], [373, 326]]]\n",
    "\n",
    "STRIDES       = np.array(YOLO_STRIDES)\n",
    "ANCHORS       = (np.array(YOLO_ANCHORS).T/STRIDES).T\n",
    "\n",
    "NUM_CLASS     = 10 # COCO 데이터이면 80, MNIST 데이터이면 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f884d2",
   "metadata": {},
   "source": [
    "## 데이터 생성기(data.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b6b3832-e5b5-4690-aeae-813faf95e848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from config import *\n",
    "from image_process import *\n",
    "from bbox_iou import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d66a4d42-0fdd-4002-8c72-6935218a194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일에서 클래스 라벨을 읽어 딕셔너리로 만들어 반환\n",
    "def read_class_names(class_label_path):\n",
    "    names = {}\n",
    "    with open(class_label_path, 'r') as data:\n",
    "        for ID, name in enumerate(data):\n",
    "            names[ID] = name.strip('\\n')\n",
    "    return names\n",
    "\n",
    "\n",
    "class DataGenerator(object):\n",
    "    def __init__(self,\n",
    "                 data_path,\n",
    "                 annot_path,\n",
    "                 class_label_path,\n",
    "                 load_images_to_ram=True,\n",
    "                 data_aug=True,\n",
    "                 input_size=416,\n",
    "                 anchor_per_scale=3,\n",
    "                 max_bbox_per_scale=100, \n",
    "                 batch_size=4,\n",
    "                 strides=STRIDES, \n",
    "                 anchors=ANCHORS):\n",
    "        self.input_size = input_size\n",
    "        self.annot_path = annot_path\n",
    "        self.batch_size = batch_size\n",
    "        self.data_aug = False\n",
    "        self.strides = strides\n",
    "        self.classes = read_class_names(class_label_path)\n",
    "        self.num_classes = len(self.classes)\n",
    "        self.anchors = anchors\n",
    "        self.anchor_per_scale = anchor_per_scale\n",
    "        self.max_bbox_per_scale = max_bbox_per_scale\n",
    "        self.load_images_to_ram = load_images_to_ram\n",
    "        self.annotations = self.load_annotations(annot_path)\n",
    "        self.num_samples = len(self.annotations)\n",
    "        self.num_batchs = int(np.ceil(self.num_samples / self.batch_size)) \n",
    "        self.batch_count = 0 \n",
    "        self.output_sizes = input_size // strides\n",
    "\n",
    "    # 아노테이션 경로에서 데이터파일을 읽어옴 \n",
    "    def load_annotations(self, annot_path):\n",
    "        # C:\\mnist_test\\000009.jpg \n",
    "        # 156,153,178,175,9 278,294,300,316,0 \n",
    "        annotations = []\n",
    "\n",
    "        with open(self.annot_path, 'r') as f:\n",
    "            # 파일에서 데이터를 불러와 라인별로 자름 \n",
    "            data = f.read().splitlines()\n",
    "            # 공백으로 잘라 맨 앞의 파일경로제외하고  \n",
    "            # 길이가0이 아닌 행들을 리스트로 만들어 놓음 \n",
    "            # 파일명만 있는 행 제거 \n",
    "            # (객체가 없는 이미지의 어노테이션 데이터임) \n",
    "            lines = [line.strip() for line in data if len(line.strip().split()[1:]) != 0]\n",
    "        # 랜덤하게 섞음 \n",
    "        np.random.shuffle(lines)\n",
    "\n",
    "        for line in lines:\n",
    "            # 공백으로 나눔 \n",
    "            # 예: line=['C:\\mnist_test\\000009.jpg', \n",
    "            # 156,153,178,175,9', '278,294,300,316,0'] \n",
    "            annotation = line.split()\n",
    "            image_path, index = \"\", 1\n",
    "            for i, one_line in enumerate(annotation):\n",
    "                if not one_line.replace(\",\",\"\").isnumeric():\n",
    "                    if image_path != \"\": \n",
    "                        image_path += \" \"\n",
    "                    image_path += one_line\n",
    "                else:\n",
    "                    index = i\n",
    "                    break\n",
    "\n",
    "            # 어노테이션 이미지파일이 없으면 예외 발생시킴 \n",
    "            if not os.path.exists(image_path):\n",
    "                raise KeyError(f\"{image_path} 파일이 없음\")\n",
    "\n",
    "            # 램 사용하면 이미지를 메모리에 저장 후 사용 \n",
    "            # 램 사용하지 않으면 \n",
    "            #    __next__에서 parse_annotation을 실행, \n",
    "            #    parse_annotation에서 이미지가 로드됨 \n",
    "            if self.load_images_to_ram:\n",
    "                image = cv2.imread(image_path)\n",
    "            else:\n",
    "                image = '' \n",
    "\n",
    "            # [['C:\\mnist_test\\000009.jpg', \n",
    "            # [156,153,178,175,9', '278,294,300,316,0'], ''], ... ] \n",
    "            annotations.append([image_path, annotation[index:], image])\n",
    "\n",
    "        return annotations\n",
    "\n",
    "    # 아노테이션 데이터 파싱 \n",
    "    def parse_annotation(self, annotation, mAP='False'):\n",
    "        if self.load_images_to_ram:\n",
    "            image_path = annotation[0]\n",
    "            image = annotation[2]\n",
    "        else:\n",
    "            image_path = annotation[0]\n",
    "            image = cv2.imread(image_path) # 이미지를 불러옴 \n",
    "\n",
    "        #  [[156,153,178,175,9], [278,294,300,316,0]] \n",
    "        bboxes = np.array([list(map(int, box.split(','))) for box in annotation[1]])\n",
    "\n",
    "        # 이미지 증강 - 숫자, 문자는 좌/우 반전이 필요 없음 \n",
    "        # 이미지를 변환하면 경계 상자도 같이 바꿔줘야 함 \n",
    "        if self.data_aug:\n",
    "            # 좌/우 반전(생략) \n",
    "#             image, bboxes = random_horizontal_flip(np.copy(image), np.copy(bboxes)) \n",
    "            # 자르기 \n",
    "            image, bboxes = random_crop(np.copy(image),\n",
    "                                        np.copy(bboxes))  \n",
    "            # 이동 \n",
    "            image, bboxes = random_translate(np.copy(image),\n",
    "                                             np.copy(bboxes))\n",
    "\n",
    "        # mAP=True이면 image, bbox를 반환\n",
    "        if mAP==True:\n",
    "            return image, bboxes\n",
    "        \n",
    "        image, bboxes = resize_to_squre(np.copy(image), self.input_size, np.copy(bboxes))\n",
    "\n",
    "        return image, bboxes\n",
    " \n",
    "    # 상자 전처리 \n",
    "    def preprocess_true_boxes(self, bboxes):\n",
    "        # 스트라이드의 수 만큼 출력 레벨이 만들어짐 \n",
    "        OUTPUT_LEVELS = len(self.strides)\n",
    "\n",
    "        # output_size = 416/[8, 16, 32] = [52, 26, 13] -> N\n",
    "        # anchor_per_scale = 3, num_classes = 10(MNIST일 경우)\n",
    "        # 출력 레벨 수 만큼 (N,N,3,15) 모양의 라벨 배열 초기화\n",
    "        label = [np.zeros((self.output_sizes[i],\n",
    "                           self.output_sizes[i],\n",
    "                           self.anchor_per_scale,\n",
    "                           5 + self.num_classes))\n",
    "                 for i in range(OUTPUT_LEVELS)]\n",
    "        # max_bbox_per_scale = 100 \n",
    "        # 출력 레벨 수 만큼 (100,4) 모양 경계상자 배열 초기화 \n",
    "        bboxes_xywh = [np.zeros((self.max_bbox_per_scale, 4))\n",
    "                       for _ in range(OUTPUT_LEVELS)]\n",
    "        # 출력 레벨 수 만큼 상자 수 배열 초기화 \n",
    "        bbox_count = np.zeros((OUTPUT_LEVELS,))\n",
    "\n",
    "        # 모든 상자 수 만큼 실행 \n",
    "        for bbox in bboxes:\n",
    "            # 상자 좌표 \n",
    "            bbox_coor = bbox[:4]\n",
    "            # 상자 클래스 라벨 \n",
    "            bbox_class_ind = bbox[4]\n",
    "            # 상자의 클래스 라벨 원-핫 인코딩\n",
    "            onehot = np.zeros(self.num_classes, dtype=np.float64) \n",
    "            onehot[bbox_class_ind] = 1.0\n",
    "\n",
    "            # 원-핫 라벨 평활화(Label Smoothing) \n",
    "            # 레이블 정규화라고 부르기도 함 \n",
    "            # 손실함수가 cross entropy이고,\n",
    "            # 활성화 함수를 softmax를 사용할 때 적용 \n",
    "            # 가장 큰 벡터가 나머지 벡터보다 커지는 것을 억제 \n",
    "            # 공식: y_ls = (1-alpha)*y_onehot + alpha/K \n",
    "            K = self.num_classes\n",
    "            alpha = 0.01 \n",
    "            smooth_onehot = (1-alpha)*onehot + alpha/K \n",
    "\n",
    "            # 상자 좌표를 상자 x,y,w,h로 변환 후 표준화 \n",
    "            bbox_xywh = np.concatenate(\n",
    "                [(bbox_coor[2:] + bbox_coor[:2]) * 0.5,\n",
    "                 bbox_coor[2:] - bbox_coor[:2]], axis=-1)\n",
    "            bbox_xywh_scaled = 1.0 * bbox_xywh[np.newaxis, :] / self.strides[:, np.newaxis] \n",
    "\n",
    "            iou = []\n",
    "            exist_positive = False \n",
    "            for i in range(OUTPUT_LEVELS):  # range(3): \n",
    "                # 앵커박스 \n",
    "                anchors_xywh = np.zeros((self.anchor_per_scale, 4))\n",
    "                anchors_xywh[:, 0:2] = np.floor(\n",
    "                    bbox_xywh_scaled[i, 0:2]).astype(np.int32)+0.5\n",
    "                anchors_xywh[:, 2:4] = self.anchors[i]\n",
    "\n",
    "                # 실제 박스와 앵커박스 IoU계산 \n",
    "                iou_scale = bbox_iou(\n",
    "                    bbox_xywh_scaled[i][np.newaxis, :],\n",
    "                    anchors_xywh)\n",
    "                iou.append(iou_scale)\n",
    "\n",
    "                # IoU가 0.3 이상인 박스만 처리함 \n",
    "                iou_mask = iou_scale > 0.3 \n",
    "                if np.any(iou_mask):\n",
    "                    xi, yi = np.floor(\n",
    "                        bbox_xywh_scaled[i, 0:2]).astype(np.int32) \n",
    "\n",
    "                    label[i][yi, xi, iou_mask, :] = 0 \n",
    "                    label[i][yi, xi, iou_mask, 0:4] = bbox_xywh\n",
    "                    label[i][yi, xi, iou_mask, 4:5] = 1.0 \n",
    "                    label[i][yi, xi, iou_mask, 5:] = smooth_onehot\n",
    "\n",
    "                    bbox_ind = int(                        bbox_count[i]%self.max_bbox_per_scale)\n",
    "                    bboxes_xywh[i][bbox_ind, :4] = bbox_xywh\n",
    "                    bbox_count[i] += 1 \n",
    "                    exist_positive = True \n",
    "  \n",
    "            if not exist_positive:\n",
    "                bst_anc_idx = np.argmax(np.array(iou).reshape(-1),\n",
    "                                        axis=-1)\n",
    "                best_detect = int(bst_anc_idx / self.anchor_per_scale)\n",
    "                best_anchor = int(bst_anc_idx % self.anchor_per_scale)\n",
    "                xi, yi = np.floor(\n",
    "                    bbox_xywh_scaled[best_detect,\n",
    "                                     0:2]).astype(np.int32)\n",
    "\n",
    "                label[best_detect][yi, xi, best_anchor, :] = 0 \n",
    "                label[best_detect][yi, xi,\n",
    "                                   best_anchor, 0:4] = bbox_xywh \n",
    "                label[best_detect][yi, xi,\n",
    "                                   best_anchor, 4:5] = 1.0 \n",
    "                label[best_detect][yi, xi,\n",
    "                                   best_anchor, 5:] = smooth_onehot \n",
    "\n",
    "                bbox_ind = int(bbox_count[best_detect] % self.max_bbox_per_scale)\n",
    "                bboxes_xywh[best_detect][bbox_ind, :4] = bbox_xywh \n",
    "                bbox_count[best_detect] += 1 \n",
    "\n",
    "        label_sbbox, label_mbbox, label_lbbox = label\n",
    "        sbboxes, mbboxes, lbboxes = bboxes_xywh\n",
    "        output_boxes = label_sbbox, label_mbbox, label_lbbox,\n",
    "        sbboxes, mbboxes, lbboxes\n",
    "        return output_boxes \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_batchs\n",
    "  \n",
    "    def __iter__(self):\n",
    "        return self \n",
    " \n",
    "    # 배치 크기만큼 이미지와 라벨 박스를 반환 \n",
    "    def __next__(self):\n",
    "        with tf.device('/cpu:0'):\n",
    "            # 배치 이미지를 갖는 배열 \n",
    "            batch_image = np.zeros( \n",
    "                (self.batch_size,\n",
    "                 self.input_size,\n",
    "                 self.input_size,\n",
    "                 3), dtype=np.float32)\n",
    " \n",
    "            # 배치 라벨(small, middle, large) 경계 상자 \n",
    "            batch_label_sbbox = np.zeros(\n",
    "                (self.batch_size,\n",
    "                 self.output_sizes[0],\n",
    "                 self.output_sizes[0],\n",
    "                 self.anchor_per_scale,\n",
    "                 5 + self.num_classes), dtype=np.float32)\n",
    "            batch_label_mbbox = np.zeros( \n",
    "                (self.batch_size,\n",
    "                 self.output_sizes[1],\n",
    "                 self.output_sizes[1],\n",
    "                 self.anchor_per_scale,\n",
    "                 5 + self.num_classes), dtype=np.float32)\n",
    "            batch_label_lbbox = np.zeros( \n",
    "                (self.batch_size,\n",
    "                 self.output_sizes[2], \n",
    "                 self.output_sizes[2], \n",
    "                 self.anchor_per_scale,\n",
    "                 5 + self.num_classes), dtype=np.float32)\n",
    " \n",
    "            # 배치 크기만큼 경계 상자를 저장할 변수 \n",
    "            batch_sbboxes = np.zeros(\n",
    "                (self.batch_size,\n",
    "                 self.max_bbox_per_scale, 4),\n",
    "                dtype=np.float32)\n",
    "            batch_mbboxes = np.zeros(\n",
    "                (self.batch_size, \n",
    "                 self.max_bbox_per_scale, 4),\n",
    "                dtype=np.float32)\n",
    "            batch_lbboxes = np.zeros( \n",
    "                (self.batch_size,\n",
    "                 self.max_bbox_per_scale, 4),\n",
    "                dtype=np.float32)\n",
    "\n",
    "            exceptions = False \n",
    "            num = 0 \n",
    "            if self.batch_count < self.num_batchs:\n",
    "                # 배치 크기만큼 실행   \n",
    "                while num < self.batch_size:  \n",
    "                    index = self.batch_count * self.batch_size + num \n",
    "                    if index >= self.num_samples: \n",
    "                        index -= self.num_samples\n",
    "                    annotation = self.annotations[index]\n",
    "                    image, bboxes = self.parse_annotation( annotation) \n",
    "                    try:\n",
    "                        label_sbbox, label_mbbox, label_lbbox, sbboxes, mbboxes, lbboxes = self.preprocess_true_boxes(bboxes) \n",
    "                    except IndexError:\n",
    "                        exceptions = True \n",
    "                        print(\"IndexError,\", annotation[0])\n",
    "\n",
    "                    batch_image[num,:,:,:] = image \n",
    "                    batch_label_mbbox[num,:,:,:,:] = label_mbbox \n",
    "                    batch_label_lbbox[num,:,:,:,:] = label_lbbox \n",
    "                    batch_mbboxes[num,:,:] = mbboxes \n",
    "                    batch_lbboxes[num,:,:] = lbboxes \n",
    "                    batch_label_sbbox[num,:,:,:,:] = label_sbbox \n",
    "                    batch_sbboxes[num,:,:] = sbboxes \n",
    "                    num += 1 \n",
    "\n",
    "                if exceptions:\n",
    "                    print('\\n')\n",
    "                    raise Exception(\"데이터셋에 문제가 있습니다.\")\n",
    "\n",
    "                self.batch_count += 1 \n",
    "                batch_sm_target = batch_label_sbbox, batch_sbboxes \n",
    "                batch_md_target = batch_label_mbbox, batch_mbboxes \n",
    "                batch_lg_target = batch_label_lbbox, batch_lbboxes \n",
    "\n",
    "                target=(batch_sm_target,batch_md_target,batch_lg_target) \n",
    "                return batch_image, target\n",
    "            else:\n",
    "                self.batch_count = 0\n",
    "                np.random.shuffle(self.annotations)\n",
    "                raise StopIteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdcb424",
   "metadata": {},
   "source": [
    "## GPU 사용 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93069a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs []\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(f'GPUs {gpus}')\n",
    "\n",
    "if len(gpus) > 0:\n",
    "    try: \n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError: \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca83c54e",
   "metadata": {},
   "source": [
    "## 상수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1748550",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGDIR = \"logs\" # 학습로그를 저장할 디렉토리\n",
    "\n",
    "WARMUP_EPOCHS = 2\n",
    "EPOCHS = 100\n",
    "\n",
    "SAVE_BEST_ONLY        = True              # val loss가 가장 좋은 모델을 저장, True 권장\n",
    "SAVE_CHECKPOINT       = False             # True이면 학습 시 모든 유효한 모델을 저장함, False 권장\n",
    "CHECKPOINTS_FOLDER    = \"checkpoints\"     # 모델이 저장될 디렉토리\n",
    "MODEL_NAME            = \"mnist_custom\"    # 저장될 모델의 이름\n",
    "SCORE_THRESHOLD       = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38437b9",
   "metadata": {},
   "source": [
    "## 학습 로그 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6e7fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "\n",
    "LOGDIR = \"logs\" # 학습 로그를 저장할 디렉토리 \n",
    "\n",
    "if os.path.exists(LOGDIR): \n",
    "    shutil.rmtree(LOGDIR) # 로그 디렉토리가 있으면 삭제 \n",
    "\n",
    "writer = tf.summary.create_file_writer(LOGDIR)\n",
    "validate_writer = tf.summary.create_file_writer(LOGDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c145aee",
   "metadata": {},
   "source": [
    "## compute_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02bd2bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(pred, conv, label, bboxes, \n",
    "                 i=0, iou_loss_thresh=0.45):\n",
    "    conv_shape  = tf.shape(conv)\n",
    "    batch_size  = conv_shape[0]\n",
    "    output_size = conv_shape[1]\n",
    "    input_size  = STRIDES[i] * output_size\n",
    "    conv = tf.reshape(conv,\n",
    "                      (batch_size, output_size, output_size,\n",
    "                       3, 5 + NUM_CLASS))\n",
    "\n",
    "    conv_raw_conf = conv[:, :, :, :, 4:5]\n",
    "    conv_raw_prob = conv[:, :, :, :, 5:]\n",
    "\n",
    "    pred_xywh     = pred[:, :, :, :, 0:4]\n",
    "    pred_conf     = pred[:, :, :, :, 4:5]\n",
    "\n",
    "    label_xywh    = label[:, :, :, :, 0:4]\n",
    "    respond_bbox  = label[:, :, :, :, 4:5]\n",
    "    label_prob    = label[:, :, :, :, 5:]\n",
    "\n",
    "    giou = tf.expand_dims(bbox_giou(pred_xywh, label_xywh), \n",
    "                          axis=-1)\n",
    "    input_size = tf.cast(input_size, tf.float32)    \n",
    "\n",
    "    bbox_loss_scale = 2.0 - 1.0 * label_xywh[:, :, :, :, 2:3] * label_xywh[:, :, :, :, 3:4] / (input_size ** 2)\n",
    "    giou_loss = respond_bbox * bbox_loss_scale * (1 - giou)\n",
    "\n",
    "    # bbox_iou \n",
    "    iou = bbox_iou(pred_xywh[:, :, :, :, np.newaxis, :],\n",
    "                   bboxes[:, np.newaxis, np.newaxis, np.newaxis, :, :]) \n",
    "\n",
    "    # 실제 상자에서 가장 큰 예측값을 갖는 상자로 IoU 값 찾기 \n",
    "    max_iou = tf.expand_dims(tf.reduce_max(iou, axis=-1),\n",
    "                             axis=-1)\n",
    "\n",
    "    # 가장 큰 iou가 임계값보다 작으면 예측 상자에 개체가 포함되지 않은 것으로 간주되고 배경 상자로 설정 \n",
    "    respond_bgd = (1.0 - respond_bbox) * tf.cast( max_iou < iou_loss_thresh, tf.float32 )\n",
    "\n",
    "    conf_focal = tf.pow(respond_bbox - pred_conf, 2)\n",
    "\n",
    "    # confidence의 손실 계산  \n",
    "    # 그리드에 객체가 포함된 경우 1, 그렇지 않을경우 0  \n",
    "    conf_loss = conf_focal * (\n",
    "        respond_bbox * tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=respond_bbox, logits=conv_raw_conf)\n",
    "        + \n",
    "        respond_bgd * tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=respond_bbox, logits=conv_raw_conf) \n",
    "    )\n",
    "\n",
    "    prob_loss = respond_bbox * tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        labels=label_prob, logits=conv_raw_prob)\n",
    "\n",
    "    giou_loss = tf.reduce_mean(tf.reduce_sum(giou_loss, axis=[1,2,3,4])) \n",
    "    conf_loss = tf.reduce_mean(tf.reduce_sum(conf_loss, axis=[1,2,3,4])) \n",
    "    prob_loss = tf.reduce_mean(tf.reduce_sum(prob_loss, axis=[1,2,3,4])) \n",
    "\n",
    "    return giou_loss, conf_loss, prob_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14709249",
   "metadata": {},
   "source": [
    "## 학습 단계 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e18d7b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, image_data, target, lr_init=1e-4, lr_end=1e-6):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_result = model(image_data, training=True)\n",
    "        giou_loss = conf_loss = prob_loss = 0\n",
    "\n",
    "        # 손실값 계산 \n",
    "        grid = 3\n",
    "        for i in range(grid):\n",
    "            conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "            loss_items = compute_loss(pred, conv, *target[i], i)\n",
    "            giou_loss += loss_items[0]\n",
    "            conf_loss += loss_items[1]\n",
    "            prob_loss += loss_items[2]\n",
    "\n",
    "        total_loss = giou_loss + conf_loss + prob_loss\n",
    "\n",
    "        gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        # 학습률 업데이트 \n",
    "        # 워밍업 참고: https://arxiv.org/abs/1812.01187\n",
    "        global_steps.assign_add(1)\n",
    "        if global_steps < warmup_steps:\n",
    "            lr = global_steps / warmup_steps * lr_init\n",
    "        else:\n",
    "            lr = lr_end + 0.5 * (lr_init - lr_end) * ((1 + tf.cos((global_steps - warmup_steps) / (total_steps - warmup_steps) * np.pi)))\n",
    "        optimizer.lr.assign(lr.numpy())\n",
    "\n",
    "        # Loss를 로그에 저장 \n",
    "        with writer.as_default():\n",
    "            tf.summary.scalar(\"lr\", optimizer.lr,\n",
    "                              step=global_steps)\n",
    "            tf.summary.scalar(\"loss/total_loss\", total_loss,\n",
    "                              step=global_steps)\n",
    "            tf.summary.scalar(\"loss/giou_loss\", giou_loss,\n",
    "                              step=global_steps)\n",
    "            tf.summary.scalar(\"loss/conf_loss\", conf_loss,\n",
    "                              step=global_steps)\n",
    "            tf.summary.scalar(\"loss/prob_loss\", prob_loss,\n",
    "                              step=global_steps)\n",
    "        writer.flush()\n",
    "\n",
    "    return global_steps.numpy(), optimizer.lr.numpy(), giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d945f35",
   "metadata": {},
   "source": [
    "## 검증 단계 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ef05b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_step(model, image_data, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_result = model(image_data, training=False)\n",
    "        giou_loss = conf_loss = prob_loss = 0 \n",
    "\n",
    "        grid = 3 \n",
    "        for i in range(grid):\n",
    "            conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "            loss_items = compute_loss(pred, conv, *target[i], i)\n",
    "            giou_loss += loss_items[0]\n",
    "            conf_loss += loss_items[1]\n",
    "            prob_loss += loss_items[2]\n",
    "\n",
    "        total_loss = giou_loss + conf_loss + prob_loss\n",
    "\n",
    "    return giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d1102b",
   "metadata": {},
   "source": [
    "# 모듈 불러와 학습 모델 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a40aa3",
   "metadata": {},
   "source": [
    "## 데이터 생성기 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdcd721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from config import *\n",
    "from data import DataGenerator \n",
    "\n",
    "trainset = DataGenerator(data_path=\"/xml\",\n",
    "                         annot_path=\"fungi_train.txt\",\n",
    "                         class_label_path=\"fungi.names\")\n",
    "testset = DataGenerator(data_path=\"/xml\", \n",
    "                        annot_path=\"fungi_test.txt\",\n",
    "                        class_label_path=\"fungi.names\")\n",
    "steps_per_epoch = len(trainset)\n",
    "global_steps = tf.Variable(1, trainable=False, dtype=tf.int64) \n",
    "warmup_steps = WARMUP_EPOCHS * steps_per_epoch\n",
    "total_steps = EPOCHS * steps_per_epoch\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36b06a2",
   "metadata": {},
   "source": [
    "## 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1a1ab4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs []\n",
      "epoch: 0 step:    2/24, lr:0.000004, giou_loss:   6.10, conf_loss:1878.61, prob_loss:   6.91, total_loss:1891.62\n",
      "epoch: 0 step:    3/24, lr:0.000006, giou_loss:   3.54, conf_loss:1788.42, prob_loss:   4.79, total_loss:1796.76\n",
      "epoch: 0 step:    4/24, lr:0.000008, giou_loss:   3.28, conf_loss:1790.18, prob_loss:   4.09, total_loss:1797.55\n",
      "epoch: 0 step:    5/24, lr:0.000010, giou_loss:   6.25, conf_loss:1762.78, prob_loss:   7.52, total_loss:1776.56\n",
      "epoch: 0 step:    6/24, lr:0.000012, giou_loss:   3.68, conf_loss:1795.96, prob_loss:   4.80, total_loss:1804.44\n",
      "epoch: 0 step:    7/24, lr:0.000015, giou_loss:   7.52, conf_loss:1731.49, prob_loss:   9.83, total_loss:1748.84\n",
      "epoch: 0 step:    8/24, lr:0.000017, giou_loss:   4.27, conf_loss:1720.48, prob_loss:   5.02, total_loss:1729.78\n",
      "epoch: 0 step:    9/24, lr:0.000019, giou_loss:   3.54, conf_loss:1674.08, prob_loss:   4.39, total_loss:1682.01\n",
      "epoch: 0 step:   10/24, lr:0.000021, giou_loss:   6.00, conf_loss:1635.05, prob_loss:   6.59, total_loss:1647.65\n",
      "epoch: 0 step:   11/24, lr:0.000023, giou_loss:   4.21, conf_loss:1610.93, prob_loss:   5.01, total_loss:1620.15\n",
      "epoch: 0 step:   12/24, lr:0.000025, giou_loss:   6.27, conf_loss:1576.09, prob_loss:   6.85, total_loss:1589.21\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m image_data, target \u001b[38;5;129;01min\u001b[39;00m trainset:\n\u001b[0;32m---> 14\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43myolo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m         cur_step \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m%\u001b[39m steps_per_epoch\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch:\u001b[39m\u001b[38;5;132;01m{:2.0f}\u001b[39;00m\u001b[38;5;124m step:\u001b[39m\u001b[38;5;132;01m{:5.0f}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, lr:\u001b[39m\u001b[38;5;132;01m{:.6f}\u001b[39;00m\u001b[38;5;124m, giou_loss:\u001b[39m\u001b[38;5;132;01m{:7.2f}\u001b[39;00m\u001b[38;5;124m, conf_loss:\u001b[39m\u001b[38;5;132;01m{:7.2f}\u001b[39;00m\u001b[38;5;124m, prob_loss:\u001b[39m\u001b[38;5;132;01m{:7.2f}\u001b[39;00m\u001b[38;5;124m, total_loss:\u001b[39m\u001b[38;5;132;01m{:7.2f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch, cur_step, steps_per_epoch, results[\u001b[38;5;241m1\u001b[39m], results[\u001b[38;5;241m2\u001b[39m], results[\u001b[38;5;241m3\u001b[39m], results[\u001b[38;5;241m4\u001b[39m], results[\u001b[38;5;241m5\u001b[39m]))\n",
      "File \u001b[0;32m~/Desktop/project/기업 프로젝트/fungi_20220620/train.py:108\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, image_data, target, lr_init, lr_end)\u001b[0m\n\u001b[1;32m    104\u001b[0m     prob_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_items[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    106\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m giou_loss \u001b[38;5;241m+\u001b[39m conf_loss \u001b[38;5;241m+\u001b[39m prob_loss\n\u001b[0;32m--> 108\u001b[0m gradients \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(gradients, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# 학습률 갱신\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# about warmup: https://arxiv.org/pdf/1812.01187.pdf\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py38_tf28/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py:1081\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_gradients \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1078\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m   1079\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mflatten(output_gradients)]\n\u001b[0;32m-> 1081\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[1;32m   1090\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py38_tf28/lib/python3.8/site-packages/tensorflow/python/eager/imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from config import *\n",
    "from bbox_iou import bbox_iou, bbox_giou\n",
    "from yolov3 import Create_YOLOv3\n",
    "from train import *\n",
    "\n",
    "\n",
    "yolo = Create_YOLOv3(num_class=NUM_CLASS, train_mode=True)\n",
    "best_val_loss = 1000 \n",
    "save_directory = os.path.join(CHECKPOINTS_FOLDER, MODEL_NAME)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for image_data, target in trainset:\n",
    "        results = train_step(yolo, image_data, target)\n",
    "        cur_step = results[0] % steps_per_epoch\n",
    "        print(\"epoch:{:2.0f} step:{:5.0f}/{}, lr:{:.6f}, giou_loss:{:7.2f}, conf_loss:{:7.2f}, prob_loss:{:7.2f}, total_loss:{:7.2f}\".format(epoch, cur_step, steps_per_epoch, results[1], results[2], results[3], results[4], results[5]))\n",
    " \n",
    "    if len(testset) == 0: \n",
    "        print(\"configure TEST options to validate model\")\n",
    "        yolo.save_weights(save_directory)\n",
    "        continue \n",
    "\n",
    "    count = 0\n",
    "    giou_val, conf_val, prob_val, total_val = 0, 0, 0, 0 \n",
    "\n",
    "    for image_data, target in testset:\n",
    "        results = validate_step(yolo, image_data, target)\n",
    "        count += 1\n",
    "        giou_val += results[0]\n",
    "        conf_val += results[1]\n",
    "        prob_val += results[2]\n",
    "        total_val += results[3]\n",
    "\n",
    "    # validation loss 저장 \n",
    "    with validate_writer.as_default():\n",
    "        tf.summary.scalar(\"validate_loss/total_val\", total_val / count, step=epoch)\n",
    "        tf.summary.scalar(\"validate_loss/giou_val\", giou_val / count, step=epoch)\n",
    "        tf.summary.scalar(\"validate_loss/conf_val\", conf_val / count, step=epoch)\n",
    "        tf.summary.scalar(\"validate_loss/prob_val\", prob_val / count, step=epoch)\n",
    "    validate_writer.flush()\n",
    "    print(\"\\n\\ngiou_val_loss:{:7.2f}, conf_val_loss:{:7.2f}, prob_val_loss:{:7.2f}, total_val_loss:{:7.2f}\\n\\n\".format( giou_val / count, conf_val / count, prob_val / count, total_val / count))\n",
    "\n",
    "    if SAVE_CHECKPOINT and not SAVE_BEST_ONLY:\n",
    "        save_directory = os.path.join(CHECKPOINTS_FOLDER,  MODEL_NAME + \"_val_loss_{:7.2f}\".format(total_val / count))\n",
    "\n",
    "    if SAVE_BEST_ONLY:\n",
    "        if best_val_loss > total_val / count:\n",
    "            best_val_loss = total_val / count\n",
    "            yolo.save_weights(save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424329d0",
   "metadata": {},
   "source": [
    "# 예측 후 후처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9eb4df",
   "metadata": {},
   "source": [
    "## 박스 후처리(postprocess_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a16091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def postprocess_boxes(pred_bbox, original_image, input_size, \n",
    "                      score_threshold):\n",
    "\n",
    "    valid_scale = [0, np.inf]\n",
    "    pred_bbox = np.array(pred_bbox)\n",
    "\n",
    "    pred_xywh = pred_bbox[:, 0:4]\n",
    "    pred_conf = pred_bbox[:, 4]\n",
    "    pred_prob = pred_bbox[:, 5:]\n",
    "\n",
    "    # 1. (x, y, w, h) --> (xmin, ymin, xmax, ymax) \n",
    "    pred_coor = np.concatenate( \n",
    "        [pred_xywh[:, :2] - pred_xywh[:, 2:] * 0.5,\n",
    "         pred_xywh[:, :2] + pred_xywh[:, 2:] * 0.5], axis=-1)\n",
    "\n",
    "    # 2. (xmin, ymin, xmax, ymax) -> (xmin_org, ymin_org, xmax_org, ymax_org) \n",
    "    org_h, org_w = original_image.shape[:2]\n",
    "    resize_ratio = min(input_size/org_w, input_size/org_h)\n",
    "\n",
    "    dw = (input_size - resize_ratio * org_w) / 2 \n",
    "    dh = (input_size - resize_ratio * org_h) / 2 \n",
    "\n",
    "    pred_coor[:, 0::2] = 1.0 * (pred_coor[:, 0::2] - dw) / resize_ratio\n",
    "    pred_coor[:, 1::2] = 1.0 * (pred_coor[:, 1::2] - dh) / resize_ratio\n",
    "\n",
    "    # 3. 범위를 벗어나는 박스를 자름 \n",
    "    pred_coor = np.concatenate(\n",
    "        [np.maximum(pred_coor[:, :2], [0, 0]),\n",
    "         np.minimum(pred_coor[:, 2:], [org_w-1, org_h-1])],\n",
    "        axis=-1)\n",
    "    invalid_mask = np.logical_or(\n",
    "        (pred_coor[:, 0] > pred_coor[:, 2]),\n",
    "        (pred_coor[:, 1] > pred_coor[:, 3]))\n",
    "    pred_coor[invalid_mask] = 0 \n",
    "\n",
    "    # 4. 유효하지 않은 상자 무시 \n",
    "    bboxes_scale = np.sqrt(\n",
    "        np.multiply.reduce(\n",
    "            pred_coor[:, 2:4] - pred_coor[:, 0:2], axis=-1))\n",
    "    scale_mask = np.logical_and(\n",
    "        (valid_scale[0] < bboxes_scale),\n",
    "        (bboxes_scale < valid_scale[1]))\n",
    "\n",
    "    # 5. 낮은 스코어의 상자 무시 \n",
    "    classes = np.argmax(pred_prob, axis=-1)\n",
    "    scores = pred_conf * pred_prob[np.arange(len(pred_coor)), classes]\n",
    "    score_mask = scores > score_threshold\n",
    "    mask = np.logical_and(scale_mask, score_mask)\n",
    "    coors, scores, classes = pred_coor[mask], scores[mask], classes[mask]\n",
    "\n",
    "    return np.concatenate([coors, scores[:, np.newaxis], \n",
    "                           classes[:, np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08c81c7",
   "metadata": {},
   "source": [
    "## 상자들의 IoU 계산하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225723b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bboxes_iou(boxes1, boxes2):\n",
    "    boxes1 = np.array(boxes1)\n",
    "    boxes2 = np.array(boxes2)\n",
    "\n",
    "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
    "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
    "\n",
    "    left_up = np.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down = np.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "\n",
    "    inter_section = np.maximum(right_down - left_up, 0.0)\n",
    "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area = boxes1_area + boxes2_area - inter_area\n",
    "\n",
    "    ious = np.maximum(1.0 * inter_area / union_area, np.finfo(np.float32).eps)\n",
    "\n",
    "    return ious"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13da1e72",
   "metadata": {},
   "source": [
    "## NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897aac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def nms(bboxes, iou_threshold, sigma=0.3, method='nms'):\n",
    "    classes_in_img = list(set(bboxes[:, 5]))\n",
    "    best_bboxes = []\n",
    "\n",
    "    for cls in classes_in_img:\n",
    "        cls_mask = (bboxes[:, 5] == cls)\n",
    "        cls_bboxes = bboxes[cls_mask]\n",
    "\n",
    "        # 1. 경계 상자의 개수가 0보다 큰지 확인  \n",
    "        while len(cls_bboxes) > 0:\n",
    "            # 2. 가장 높은 점수를 갖는 경계 상자를 선택 \n",
    "            max_ind = np.argmax(cls_bboxes[:, 4])\n",
    "            best_bbox = cls_bboxes[max_ind]\n",
    "            best_bboxes.append(best_bbox)\n",
    "            cls_bboxes = np.concatenate(\n",
    "                [cls_bboxes[: max_ind], \n",
    "                 cls_bboxes[max_ind + 1:]])\n",
    "  \n",
    "            # 3. 경계 상자의 모든 iou를 계산하고 iou 값이 임계값보다 높은 경계 상자를 제거 \n",
    "            iou = bboxes_iou(best_bbox[np.newaxis, :4],\n",
    "                             cls_bboxes[:, :4])\n",
    "            weight = np.ones((len(iou),), dtype=np.float32)\n",
    "\n",
    "            assert method in ['nms', 'soft-nms']\n",
    "\n",
    "            if method == 'nms':\n",
    "                iou_mask = iou > iou_threshold\n",
    "                weight[iou_mask] = 0.0 \n",
    "\n",
    "            if method == 'soft-nms':\n",
    "                weight = np.exp(-(1.0 * iou ** 2 / sigma))\n",
    "\n",
    "            cls_bboxes[:, 4] = cls_bboxes[:, 4] * weight\n",
    "            score_mask = cls_bboxes[:, 4] > 0. \n",
    "            cls_bboxes = cls_bboxes[score_mask]\n",
    "\n",
    "    return best_bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925645ca",
   "metadata": {},
   "source": [
    "## 사각형 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b20e884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def draw_bbox(image, bboxes, class_names,\n",
    "              show_label=True, show_confidence=True,\n",
    "              Text_colors=(0,0,0), rectangle_colors='', \n",
    "              tracking=False):\n",
    "    image_h, image_w, _ = image.shape\n",
    "    num_class = len(class_names)\n",
    "\n",
    "    hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
    "\n",
    "    random.seed(0)\n",
    "    random.shuffle(colors)\n",
    "    random.seed(None)\n",
    "\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        coor = np.array(bbox[:4], dtype=np.int32)\n",
    "        score = bbox[4]\n",
    "        class_ind = int(bbox[5])\n",
    "        bbox_color = rectangle_colors if rectangle_colors != '' else colors[class_ind]\n",
    "        bbox_thick = int(0.6 * (image_h + image_w) / 1000)\n",
    "        if bbox_thick < 1: bbox_thick = 1 \n",
    "        fontScale = 0.75 * bbox_thick\n",
    "        x1, y1 = coor[0], coor[1]\n",
    "        x2, y2 = coor[2], coor[3]\n",
    "\n",
    "        # 경계상자 그리기 \n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), \n",
    "                      bbox_color, bbox_thick * 2)\n",
    "\n",
    "        if show_label:\n",
    "            score_str = \"\" \n",
    "            if show_confidence:\n",
    "                score_str = \" {:.2f}\".format(score)\n",
    "            if tracking: \n",
    "                score_str = \" \" + str(score)\n",
    "\n",
    "            try:\n",
    "                label = f\"{_class_names[class_ind]}{score_str}\"\n",
    "            except KeyError:\n",
    "                print(\"클래스 라벨이 잘못되었습니다.\")\n",
    "\n",
    "            # 텍스트 크기 \n",
    "            (text_width, text_height), baseline = cv2.getTextSize(\n",
    "                label, cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "                fontScale, thickness=bbox_thick)\n",
    "            # 텍스트를 출력할 채워진 사각형 \n",
    "            cv2.rectangle(image, (x1, y1), \n",
    "                          (x1 + text_width,\n",
    "                           y1 - text_height - baseline),\n",
    "                          bbox_color, thickness=cv2.FILLED)\n",
    "            # 사각형 위에 텍스트 출력 \n",
    "            cv2.putText(image, label, (x1, y1 - 4), \n",
    "                        cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "                        fontScale, Text_colors, bbox_thick,\n",
    "                        lineType=cv2.LINE_AA)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db3bc7b",
   "metadata": {},
   "source": [
    "# 실시간 객체 탐지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb0f26a",
   "metadata": {},
   "source": [
    "## detect_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e766c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "from image_process import resize_to_square\n",
    "from data import read_class_names\n",
    "from post_process import *\n",
    "\n",
    "def detect_image(model, image_path, output_path,\n",
    "                 class_label_path, \n",
    "                 input_size=416, show=False,\n",
    "                 score_threshold=0.3, iou_threshold=0.45,\n",
    "                 rectangle_colors=''):\n",
    "    original_image = cv2.imread(image_path)\n",
    "    class_names = read_class_names(class_label_path)\n",
    "\n",
    "    image_data = resize_to_square(np.copy(original_image), target_size=input_size)\n",
    "    image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
    "\n",
    "    pred_bbox = model.predict(image_data)\n",
    "\n",
    "    pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
    "    pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "\n",
    "    bboxes = postprocess_boxes(pred_bbox, original_image,\n",
    "                               input_size, score_threshold)\n",
    "    bboxes = nms(bboxes, iou_threshold, method='nms')\n",
    "\n",
    "    image = draw_bbox(original_image, bboxes, class_names,\n",
    "                      rectangle_colors=rectangle_colors)\n",
    "\n",
    "    if output_path != '':\n",
    "        cv2.imwrite(output_path, image)\n",
    "    if show:\n",
    "        cv2.imshow(\"predicted image\", image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cb23fa",
   "metadata": {},
   "source": [
    "## detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84df8dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASS = 10\n",
    "from yolov3 import Create_YOLOv3\n",
    "\n",
    "yolo = Create_YOLOv3(num_class=NUM_CLASS)\n",
    "yolo.load_weights(\"checkpoints/mnist_custom\")\n",
    "weight = yolo.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee631c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo.set_weights(weight)\n",
    "result_image = detect_image(model=yolo,  \n",
    "                            image_path=\"mnist_test_c.jpg\",\n",
    "                            output_path=\"mnist_test_out.jpg\", \n",
    "                            class_label_path=\"mnist.names\", \n",
    "                            input_size=416, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70606f10",
   "metadata": {},
   "source": [
    "## Realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654aa3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from image_process import resize_to_square\n",
    "from data import read_class_names\n",
    "from post_process import *\n",
    "from yolov3 import Create_YOLOv3\n",
    "\n",
    "yolo = Create_YOLOv3(num_class=10)\n",
    "yolo.load_weights(\"checkpoints/mnist_custom\")\n",
    "weights = yolo.get_weights()\n",
    "class_names = read_class_names(\"mnist.names\")\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "if cap.isOpened():\n",
    "    while True:\n",
    "        yolo.set_weights(weights)\n",
    "        ret, image = cap.read()\n",
    "        if not ret:\n",
    "            print(\"프레임을 받지 못했습니다.\")\n",
    "            break \n",
    "\n",
    "        # 밝기를 100만큼 더함 \n",
    "        dummy = np.full(image.shape, fill_value=100, \n",
    "                        dtype=np.uint8)\n",
    "        cv2.add(image, dummy, image)\n",
    "                \n",
    "        # 콘트라스트 강조함 \n",
    "        image = cv2.normalize(image, None, 0, 255,\n",
    "                              cv2.NORM_MINMAX)\n",
    "\n",
    "        # 이미지를 정사각형 모양으로 만듬 \n",
    "        image_data = resize_to_square(np.copy(image), 416)\n",
    "        image_data = image_data[np.newaxis,\n",
    "                                ...].astype(np.float32)\n",
    "\n",
    "        # 상자 예측 \n",
    "        pred_box = yolo.predict(image_data)\n",
    "        pred_box = [tf.reshape(x, (-1, tf.shape(x)[-1])) \n",
    "                    for x in pred_box]\n",
    "        pred_box = tf.concat(pred_box, axis=0)\n",
    "\n",
    "        # 상자 후처리 \n",
    "        bboxes = postprocess_boxes(pred_box, image, 416, 0.3)\n",
    "\n",
    "        # NMS에 의해 해당 영역에서 상자 하나만 남김 \n",
    "        bboxes = nms(bboxes, 0.45, method=\"nms\")\n",
    "\n",
    "        # 상자를 그림 \n",
    "        image = draw_bbox(image, bboxes, class_names)\n",
    "\n",
    "        cv2.imshow(\"Image\", image)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "else:\n",
    "    print('연결된 카메라가 없습니다.')\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf296f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec9cb9f-8324-464f-a517-9f87f7518fdc",
   "metadata": {},
   "source": [
    "# Depemdencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76d5d605-2bb5-4830-bd34-7e6e3b0e5975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be252e9f-cf06-4b2c-bbcf-6c52fac933a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num2class = {\"0.0\" : \"buffalo\", \"1.0\" : \"elephant\", \"2.0\" : \"rhino\", \"3.0\" : \"zebra\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee0b180-33aa-4b5c-be42-809f800804a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box : (centerX, centerY, width, height)\n",
    "def convertToAbsoluteValues(size, box):\n",
    "    \n",
    "    xIn = round(((2 * float(box[0]) - float(box[2])) * size[0] / 2))\n",
    "    yIn = round(((2 * float(box[1]) - float(box[3])) * size[1] / 2))\n",
    "    xEnd = xIn + round(float(box[2]) * size[0])\n",
    "    yEnd = yIn + round(float(box[3]) * size[1])\n",
    "    \n",
    "    if xIn < 0:\n",
    "        xIn = 0\n",
    "    if yIn < 0:\n",
    "        yIn = 0\n",
    "    if xEnd >= size[0]:\n",
    "        xEnd = size[0] - 1\n",
    "    if yEnd >= size[1]:\n",
    "        yEnd = size[1] - 1\n",
    "    return (xIn, yIn, xEnd, yEnd)\n",
    "\n",
    "# def convertToRelativeValues(size, box):\n",
    "#     dw = 1. / (size[0])\n",
    "#     dh = 1. / (size[1])\n",
    "#     cx = (box[1] + box[0]) / 2.0\n",
    "#     cy = (box[3] + box[2]) / 2.0\n",
    "#     w = box[1] - box[0]\n",
    "#     h = box[3] - box[2]\n",
    "#     x = cx * dw\n",
    "#     y = cy * dh\n",
    "#     w = w * dw\n",
    "#     h = h * dh\n",
    "#     # x,y => (bounding_box_center)/width_of_the_image\n",
    "#     # w => bounding_box_width / width_of_the_image\n",
    "#     # h => bounding_box_height / height_of_the_image\n",
    "#     return (x, y, w, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4826ef4-594d-4ccc-acec-4478727ff8d3",
   "metadata": {},
   "source": [
    "# Bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4e6498-ab29-43e2-8ff1-b6e3eb62829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundingBoxes(labelPath, imagePath):\n",
    "    \n",
    "    detections, groundtruths, classes = [], [], []\n",
    "    \n",
    "    for boxtype in os.listdir(labelPath):\n",
    "\n",
    "        boxtypeDir = os.path.join(labelPath,boxtype)\n",
    "\n",
    "        for labelfile in os.listdir(boxtypeDir):\n",
    "            filename = os.path.splitext(labelfile)[0]\n",
    "            with open(os.path.join(boxtypeDir, labelfile)) as f:\n",
    "                labelinfos = f.readlines()\n",
    "\n",
    "            imgfilepath = os.path.join(imagePath, filename + \".jpg\")\n",
    "            img = cv.imread(imgfilepath)\n",
    "            h, w, _ = img.shape\n",
    "\n",
    "            for labelinfo in labelinfos:\n",
    "                label, conf, rx1, ry1, rx2, ry2 = map(float, labelinfo.strip().split())\n",
    "                x1, y1, x2, y2 = convertToAbsoluteValues((w, h), (rx1, ry1, rx2, ry2))\n",
    "                boxinfo = [filename, label, conf, (x1, y1, x2, y2)]\n",
    "                \n",
    "                if label not in classes:\n",
    "                    classes.append(label)\n",
    "                \n",
    "                if boxtype == \"detection\":\n",
    "                    detections.append(boxinfo)\n",
    "                else:\n",
    "                    groundtruths.append(boxinfo)\n",
    "                    \n",
    "    classes = sorted(classes)\n",
    "                \n",
    "    return detections, groundtruths, classes\n",
    "\n",
    "detections, groundtruths, classes = boundingBoxes(\"label\", \"image\")\n",
    "print(detections)\n",
    "print(groundtruths)\n",
    "print(classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52181f4-7e7b-40a9-9de8-9beda151c6ba",
   "metadata": {},
   "source": [
    "# Plot Bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6623fe82-cd4f-4eb3-ada9-5cbffd08bec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxPlot(boxlist, imagePath, savePath):\n",
    "    labelfiles = sorted(list(set([filename for filename, _, _, _ in boxlist])))\n",
    "    \n",
    "    for labelfile in labelfiles:\n",
    "    \n",
    "        rectinfos = []\n",
    "        imgfilePath = os.path.join(imagePath, labelfile + \".jpg\")\n",
    "        img = cv.imread(imgfilePath)\n",
    "\n",
    "        for filename, _, conf, (x1, y1, x2, y2) in boxlist:\n",
    "            if labelfile == filename:\n",
    "                rectinfos.append((x1, y1, x2, y2, conf))\n",
    "                \n",
    "        for x1, y1, x2, y2, conf in rectinfos:\n",
    "            \n",
    "            if conf == 1.0:\n",
    "                rectcolor = (0, 255, 0)\n",
    "            else:\n",
    "                rectcolor = (0, 0, 255)\n",
    "                \n",
    "            cv.rectangle(img, (x1, y1), (x2, y2), rectcolor, 4)\n",
    "        cv.imwrite(f\"{savePath}/{labelfile}.jpg\", img)\n",
    "\n",
    "        img = mpimg.imread(f\"{savePath}/{labelfile}.jpg\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "# boxPlot(detections, \"image\", savePath=\"boxed_images/detection\")\n",
    "# boxPlot(groundtruths, \"image\", savePath=\"boxed_images/groundtruth\")\n",
    "boxPlot(detections + groundtruths, \"image\", savePath=\"boxed_images/both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add9745d-d234-4ec7-b18e-1f86a20374a8",
   "metadata": {},
   "source": [
    "# IOU(Intersection over Union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ea2c0f-d6a5-4948-8ed5-3cdd3ff3f668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArea(box):\n",
    "    return (box[2] - box[0] + 1) * (box[3] - box[1] + 1)\n",
    "\n",
    "\n",
    "def getUnionAreas(boxA, boxB, interArea=None):\n",
    "    area_A = getArea(boxA)\n",
    "    area_B = getArea(boxB)\n",
    "    \n",
    "    if interArea is None:\n",
    "        interArea = getIntersectionArea(boxA, boxB)\n",
    "        \n",
    "    return float(area_A + area_B - interArea)\n",
    "\n",
    "def getIntersectionArea(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    # intersection area\n",
    "    return (xB - xA + 1) * (yB - yA + 1)\n",
    "\n",
    "# boxA = (Ax1,Ay1,Ax2,Ay2)\n",
    "# boxB = (Bx1,By1,Bx2,By2)\n",
    "def boxesIntersect(boxA, boxB):\n",
    "    if boxA[0] > boxB[2]:\n",
    "        return False  # boxA is right of boxB\n",
    "    if boxB[0] > boxA[2]:\n",
    "        return False  # boxA is left of boxB\n",
    "    if boxA[3] < boxB[1]:\n",
    "        return False  # boxA is above boxB\n",
    "    if boxA[1] > boxB[3]:\n",
    "        return False  # boxA is below boxB\n",
    "    return True\n",
    "\n",
    "def iou(boxA, boxB):\n",
    "    # if boxes dont intersect\n",
    "    if boxesIntersect(boxA, boxB) is False:\n",
    "        return 0\n",
    "    interArea = getIntersectionArea(boxA, boxB)\n",
    "    union = getUnionAreas(boxA, boxB, interArea=interArea)\n",
    "    \n",
    "    # intersection over union\n",
    "    result = interArea / union\n",
    "    assert result >= 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de38552e-4cae-404c-9eed-60b0581dad43",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxA = detections[-1][-1]\n",
    "boxB = groundtruths[-1][-1]\n",
    "\n",
    "print(f\"boxA coordinates : {(boxA)}\")\n",
    "print(f\"boxA area : {getArea(boxA)}\")\n",
    "print(f\"boxB coordinates : {(boxB)}\")\n",
    "print(f\"boxB area : {getArea(boxB)}\")\n",
    "\n",
    "print(f\"Union area of boxA and boxB : {getUnionAreas(boxA, boxB)}\")\n",
    "\n",
    "print(f\"Does boxes Intersect? : {boxesIntersect(boxA, boxB)}\")\n",
    "\n",
    "print(f\"Intersection area of boxA and boxB : {getIntersectionArea(boxA, boxB)}\")\n",
    "\n",
    "print(f\"IoU of boxA and boxB : {iou(boxA, boxB)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def8f900-0ac9-45a8-8c46-164f3359562c",
   "metadata": {},
   "source": [
    "# AP(Average Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fe251f-8dac-4a76-b2a1-1aadde0fc402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAveragePrecision(rec, prec):\n",
    "    \n",
    "    mrec = [0] + [e for e in rec] + [1]\n",
    "    mpre = [0] + [e for e in prec] + [0]\n",
    "\n",
    "    for i in range(len(mpre)-1, 0, -1):\n",
    "        mpre[i-1] = max(mpre[i-1], mpre[i])\n",
    "\n",
    "    ii = []\n",
    "\n",
    "    for i in range(len(mrec)-1):\n",
    "        if mrec[1:][i] != mrec[0:-1][i]:\n",
    "            ii.append(i+1)\n",
    "\n",
    "    ap = 0\n",
    "    for i in ii:\n",
    "        ap = ap + np.sum((mrec[i] - mrec[i-1]) * mpre[i])\n",
    "    \n",
    "    return [ap, mpre[0:len(mpre)-1], mrec[0:len(mpre)-1], ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d90d73-a93e-4951-9b8e-aad499f4552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ElevenPointInterpolatedAP(rec, prec):\n",
    "\n",
    "    mrec = [e for e in rec]\n",
    "    mpre = [e for e in prec]\n",
    "\n",
    "    recallValues = np.linspace(0, 1, 11)\n",
    "    recallValues = list(recallValues[::-1])\n",
    "    rhoInterp, recallValid = [], []\n",
    "\n",
    "    for r in recallValues:\n",
    "        argGreaterRecalls = np.argwhere(mrec[:] >= r)\n",
    "        pmax = 0\n",
    "\n",
    "        if argGreaterRecalls.size != 0:\n",
    "            pmax = max(mpre[argGreaterRecalls.min():])\n",
    "\n",
    "        recallValid.append(r)\n",
    "        rhoInterp.append(pmax)\n",
    "\n",
    "    ap = sum(rhoInterp) / 11\n",
    "\n",
    "    return [ap, rhoInterp, recallValues, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870e9794-382e-4231-9543-a802c1d2bd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AP(detections, groundtruths, classes, IOUThreshold = 0.3, method = 'AP'):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for c in classes:\n",
    "\n",
    "        dects = [d for d in detections if d[1] == c]\n",
    "        gts = [g for g in groundtruths if g[1] == c]\n",
    "\n",
    "        npos = len(gts)\n",
    "\n",
    "        dects = sorted(dects, key = lambda conf : conf[2], reverse=True)\n",
    "\n",
    "        TP = np.zeros(len(dects))\n",
    "        FP = np.zeros(len(dects))\n",
    "\n",
    "        det = Counter(cc[0] for cc in gts)\n",
    "\n",
    "        # 각 이미지별 ground truth box의 수\n",
    "        # {99 : 2, 380 : 4, ....}\n",
    "        # {99 : [0, 0], 380 : [0, 0, 0, 0], ...}\n",
    "        for key, val in det.items():\n",
    "            det[key] = np.zeros(val)\n",
    "\n",
    "\n",
    "        for d in range(len(dects)):\n",
    "\n",
    "\n",
    "            gt = [gt for gt in gts if gt[0] == dects[d][0]]\n",
    "\n",
    "            iouMax = 0\n",
    "\n",
    "            for j in range(len(gt)):\n",
    "                iou1 = iou(dects[d][3], gt[j][3])\n",
    "                if iou1 > iouMax:\n",
    "                    iouMax = iou1\n",
    "                    jmax = j\n",
    "\n",
    "            if iouMax >= IOUThreshold:\n",
    "                if det[dects[d][0]][jmax] == 0:\n",
    "                    TP[d] = 1\n",
    "                    det[dects[d][0]][jmax] = 1\n",
    "                else:\n",
    "                    FP[d] = 1\n",
    "            else:\n",
    "                FP[d] = 1\n",
    "\n",
    "        acc_FP = np.cumsum(FP)\n",
    "        acc_TP = np.cumsum(TP)\n",
    "        rec = acc_TP / npos\n",
    "        prec = np.divide(acc_TP, (acc_FP + acc_TP))\n",
    "\n",
    "        if method == \"AP\":\n",
    "            [ap, mpre, mrec, ii] = calculateAveragePrecision(rec, prec)\n",
    "        else:\n",
    "            [ap, mpre, mrec, _] = ElevenPointInterpolatedAP(rec, prec)\n",
    "\n",
    "        r = {\n",
    "            'class' : c,\n",
    "            'precision' : prec,\n",
    "            'recall' : rec,\n",
    "            'AP' : ap,\n",
    "            'interpolated precision' : mpre,\n",
    "            'interpolated recall' : mrec,\n",
    "            'total positives' : npos,\n",
    "            'total TP' : np.sum(TP),\n",
    "            'total FP' : np.sum(FP)\n",
    "        }\n",
    "\n",
    "        result.append(r)\n",
    "\n",
    "    return result\n",
    "\n",
    "result = AP(detections, groundtruths, classes)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf403659-0961-4958-8d79-565f7d2dd578",
   "metadata": {},
   "source": [
    "# mAP(mean Average Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a68eab4-6fad-413c-8f8d-3265a4c01a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mAP(result):\n",
    "    ap = 0\n",
    "    for r in result:\n",
    "        ap += r['AP']\n",
    "    mAP = ap / len(result)\n",
    "    \n",
    "    return mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a87f2b0-c45e-4986-b03f-2ef3710c5c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in result:\n",
    "    print(\"{:^8} AP : {}\".format(num2class[str(r['class'])], r['AP']))\n",
    "print(\"---------------------------\")\n",
    "print(f\"mAP : {mAP(result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb537ae-08de-4efb-a7c8-e1ca88de4068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b174ca90-8e55-478f-b7cf-d12ba8bd1cae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "300px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
